<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta name=generator content="Hugo 0.139.0"><meta name=theme content='FixIt v0.3.15'><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>fengchen</title><meta name=author content="fengchen"><meta name=description content><meta itemprop=name content="fengchen"><meta itemprop=datePublished content="2025-12-18T10:33:12+08:00"><meta itemprop=dateModified content="2025-12-18T10:33:12+08:00"><meta property="og:url" content="http://fengchen321.github.io/"><meta property="og:site_name" content="fengchen"><meta property="og:title" content="fengchen"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="fengchen"><meta name=application-name content="FixIt"><meta name=apple-mobile-web-app-title content="FixIt"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical type=text/html href=http://fengchen321.github.io/ title=fengchen><link rel=alternate type=application/rss+xml href=http://fengchen321.github.io/index.xml title=fengchen><link rel=search type=application/json href=http://fengchen321.github.io/search.json title=fengchen><link rel=stylesheet href=/css/style.min.css><link rel=preload href=/lib/fontawesome-free/all.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload href=/lib/animate/animate.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","url":"http:\/\/fengchen321.github.io\/","inLanguage":"zh-CN","author":{"@type":"Person","name":"fengchen"},"name":"fengchen"}</script><script src=/js/head/color-scheme.min.js></script></head><body data-header-desktop=sticky data-header-mobile=auto><div class=wrapper data-page-style=normal><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=fengchen><span class=header-title-text>fengchen</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/about/ title=关于本站>关于本站</a></li><li class=menu-item><a class=menu-link href=/posts/>所有文章</a></li><li class=menu-item><a class=menu-link href=/tags/>标签</a></li><li class=menu-item><a class=menu-link href=/categories/>分类</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=fengchen><span class=header-title-text>fengchen</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/about/ title=关于本站>关于本站</a></li><li class=menu-item><a class=menu-link href=/posts/>所有文章</a></li><li class=menu-item><a class=menu-link href=/tags/>标签</a></li><li class=menu-item><a class=menu-link href=/categories/>分类</a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=container><div class="page home posts"><article class="single summary" itemscope itemtype=http://schema.org/Article><h2 class=single-title itemprop="name headline"><a href=/posts/computer/linux%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/>Linx常用指令</a></h2><div class=post-meta><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
fengchen</span></span>&nbsp;<span class=post-publish title='2023-06-15 13:33:12'>发布于 <time datetime=2023-06-15>2023-06-15</time></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/computer/ class=post-category title="分类 - Computer"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Computer</a></span></div><div class=content><h3 id=linux基础 class=heading-element><span>Linux基础</span>
<a href=#linux%e5%9f%ba%e7%a1%80 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h3 id=1-linux启动 class=heading-element><span>1. Linux启动</span>
<a href=#1-linux%e5%90%af%e5%8a%a8 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ol><li><p>内核引导。</p></div><div class=post-footer><a href=/posts/computer/linux%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/>阅读全文</a><div class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/computer/ class=post-tag>Computer</a><a href=/tags/linux/ class=post-tag>Linux</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><h2 class=single-title itemprop="name headline"><a href=/posts/deeplearning/transformer_nlp/bert/>BERT</a></h2><div class=post-meta><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
fengchen</span></span>&nbsp;<span class=post-publish title='2023-06-10 18:22:27'>发布于 <time datetime=2023-06-10>2023-06-10</time></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/deep-learning/ class=post-category title="分类 - Deep Learning"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Deep Learning</a></span></div><div class=content><h3 id=bert class=heading-element><span>BERT</span>
<a href=#bert class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><blockquote><p>文章标题：<a href=https://arxiv.org/abs/1810.04805 target=_blank rel="external nofollow noopener noreferrer">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>
作者：Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova
发表时间：(NAACL-HLT 2019)</p></div><div class=post-footer><a href=/posts/deeplearning/transformer_nlp/bert/>阅读全文</a><div class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/deep-learning/ class=post-tag>Deep Learning</a><a href=/tags/transformer/ class=post-tag>Transformer</a><a href=/tags/nlp/ class=post-tag>NLP</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><h2 class=single-title itemprop="name headline"><a href=/posts/deeplearning/transformer_nlp/transformer/>Transformer</a></h2><div class=post-meta><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
fengchen</span></span>&nbsp;<span class=post-publish title='2023-06-10 18:22:27'>发布于 <time datetime=2023-06-10>2023-06-10</time></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/deep-learning/ class=post-category title="分类 - Deep Learning"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Deep Learning</a></span></div><div class=content><h3 id=transformer class=heading-element><span>Transformer</span>
<a href=#transformer class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><blockquote><p>文章标题：<a href=https://arxiv.org/abs/1706.03762# target=_blank rel="external nofollow noopener noreferrer">Attention Is All You Need</a>
作者：Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin
发表时间：(NIPS 2017)</p></div><div class=post-footer><a href=/posts/deeplearning/transformer_nlp/transformer/>阅读全文</a><div class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/deep-learning/ class=post-tag>Deep Learning</a><a href=/tags/transformer/ class=post-tag>Transformer</a><a href=/tags/nlp/ class=post-tag>NLP</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><h2 class=single-title itemprop="name headline"><a href=/posts/deeplearning/transformer_cv/mae/>MAE</a></h2><div class=post-meta><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
fengchen</span></span>&nbsp;<span class=post-publish title='2023-06-09 18:22:27'>发布于 <time datetime=2023-06-09>2023-06-09</time></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/deep-learning/ class=post-category title="分类 - Deep Learning"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Deep Learning</a></span></div><div class=content><h3 id=mae class=heading-element><span>MAE</span>
<a href=#mae class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><blockquote><p>文章标题：<a href=https://arxiv.org/abs/2111.06377 target=_blank rel="external nofollow noopener noreferrer">Masked Autoencoders Are Scalable Vision Learners</a>
作者：Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, Ross Girshick</p></div><div class=post-footer><a href=/posts/deeplearning/transformer_cv/mae/>阅读全文</a><div class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/deep-learning/ class=post-tag>Deep Learning</a><a href=/tags/transformer/ class=post-tag>Transformer</a><a href=/tags/cv/ class=post-tag>CV</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><h2 class=single-title itemprop="name headline"><a href=/posts/deeplearning/transformer_cv/vit/>VIT</a></h2><div class=post-meta><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
fengchen</span></span>&nbsp;<span class=post-publish title='2023-06-09 18:22:27'>发布于 <time datetime=2023-06-09>2023-06-09</time></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/deep-learning/ class=post-category title="分类 - Deep Learning"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Deep Learning</a></span></div><div class=content><p>[toc]</p><h3 id=vision-transformer-vit class=heading-element><span>Vision Transformer (VIT)</span>
<a href=#vision-transformer-vit class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><blockquote><p>文章标题：<a href=https://arxiv.org/abs/2010.11929 target=_blank rel="external nofollow noopener noreferrer">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a>
作者：Alexey Dosovitskiy; Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,Xiaohua Zhai
发表时间：(ICLR 2021)</p></div><div class=post-footer><a href=/posts/deeplearning/transformer_cv/vit/>阅读全文</a><div class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/deep-learning/ class=post-tag>Deep Learning</a><a href=/tags/transformer/ class=post-tag>Transformer</a><a href=/tags/cv/ class=post-tag>CV</a></div></div></article><article class="single summary" itemscope itemtype=http://schema.org/Article><h2 class=single-title itemprop="name headline"><a href=/posts/deeplearning/multimodal-learning/albef/>ALBEF</a></h2><div class=post-meta><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
fengchen</span></span>&nbsp;<span class=post-publish title='2023-06-08 18:22:27'>发布于 <time datetime=2023-06-08>2023-06-08</time></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/deep-learning/ class=post-category title="分类 - Deep Learning"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Deep Learning</a></span></div><div class=content><h3 id=albef class=heading-element><span>ALBEF</span>
<a href=#albef class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><blockquote><p>文章标题：<a href=https://arxiv.org/abs/2107.07651 target=_blank rel="external nofollow noopener noreferrer">Align before Fuse: Vision and Language Representation Learning with Momentum Distillation</a> <a href=https://www.semanticscholar.org/paper/Align-before-Fuse%3A-Vision-and-Language-Learning-Li-Selvaraju/b82c5f9efdb2ae56baa084ca41aeddd8a665c1d1 target=_blank rel="external nofollow noopener noreferrer"><img loading=lazy src="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fb82c5f9efdb2ae56baa084ca41aeddd8a665c1d1%3Ffields%3DcitationCount" alt=citation srcset="https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fb82c5f9efdb2ae56baa084ca41aeddd8a665c1d1%3Ffields%3DcitationCount&amp;size=small, https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fb82c5f9efdb2ae56baa084ca41aeddd8a665c1d1%3Ffields%3DcitationCount&amp;size=medium 1.5x, https://img.shields.io/badge/dynamic/json?label=citation&amp;query=citationCount&amp;url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fb82c5f9efdb2ae56baa084ca41aeddd8a665c1d1%3Ffields%3DcitationCount&amp;size=large 2x" data-title=citation class="suffix-invalid suffix-invalid__small suffix-invalid__large" style="background:url(/images/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title;for(const e of["style","data-title","onerror","onload"])this.removeAttribute(e)'></a></p></div><div class=post-footer><a href=/posts/deeplearning/multimodal-learning/albef/>阅读全文</a><div class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/deep-learning/ class=post-tag>Deep Learning</a><a href=/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AD%A6%E4%B9%A0/ class=post-tag>多模态学习</a></div></div></article><ul class=pagination><li class=page-item><span class=page-link><a href=/>1</a></span></li><li class=page-item><span class=page-link><a href=/page/2/>2</a></span></li><li class=page-item><span class=page-link><a href=/page/3/>3</a></span></li><li class="page-item active"><span class=page-link><a href=/page/4/>4</a></span></li><li class=page-item><span class=page-link><a href=/page/5/>5</a></span></li><li class=page-item><span class=page-link><a href=/page/6/>6</a></span></li><li class=page-item><span class=page-link aria-hidden=true>&mldr;</span></li><li class=page-item><span class=page-link><a href=/page/10/>10</a></span></li></ul></div></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.139.0"><img class=hugo-icon src=/images/hugo.min.svg alt="Hugo logo"> Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.3.15"><img class=fixit-icon src=/images/fixit.min.svg alt="FixIt logo"> FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2024 - 2026</span><span class=author itemprop=copyrightHolder>
<a href=/>fengchen</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class="variant-numeric d-none">0%</span></div></div><div id=mask></div><div class=reading-progress-bar style=left:0;top:0></div><noscript><div class=noscript-warning>该网站在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=preload href=/lib/katex/katex.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/katex/katex.min.css></noscript><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><script src=/lib/autocomplete/autocomplete.min.js defer></script><script src=/lib/sharer/sharer.min.js async defer></script><script src=/lib/katex/katex.min.js defer></script><script src=/lib/katex/auto-render.min.js defer></script><script src=/lib/katex/copy-tex.min.js defer></script><script src=/lib/katex/mhchem.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.js defer></script><script>window.config={code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:100},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50},version:"v0.3.15"}</script><script src=/js/theme.min.js defer></script></body></html>