<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>Re-Parameterization - fengchen</title><meta name=author content="fengchen"><meta name=description content="Re-parameterization"><meta name=keywords content='Deep Learning,轻量级网络'><meta itemprop=name content="Re-parameterization"><meta itemprop=description content="Re-parameterization"><meta itemprop=datePublished content="2023-06-03T18:22:27+08:00"><meta itemprop=dateModified content="2023-06-03T18:22:27+08:00"><meta itemprop=wordCount content="2171"><meta itemprop=keywords content="Deep Learning,轻量级网络"><meta property="og:url" content="http://fengchen321.github.io/posts/deeplearning/light-weight/re-parameterization/"><meta property="og:site_name" content="fengchen"><meta property="og:title" content="Re-parameterization"><meta property="og:description" content="Re-parameterization"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-06-03T18:22:27+08:00"><meta property="article:modified_time" content="2023-06-03T18:22:27+08:00"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="轻量级网络"><meta name=twitter:card content="summary"><meta name=twitter:title content="Re-parameterization"><meta name=twitter:description content="Re-parameterization"><meta name=application-name content="FixIt"><meta name=apple-mobile-web-app-title content="FixIt"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical type=text/html href=http://fengchen321.github.io/posts/deeplearning/light-weight/re-parameterization/ title="Re-parameterization - fengchen"><link rel=prev type=text/html href=http://fengchen321.github.io/posts/deeplearning/light-weight/shufflenet/ title=ShuffleNet><link rel=next type=text/html href=http://fengchen321.github.io/posts/deeplearning/light-weight/nas/ title=NAS><link rel=alternate type=text/markdown href=http://fengchen321.github.io/posts/deeplearning/light-weight/re-parameterization/index.md title="Re-parameterization - fengchen"><link rel=stylesheet href=/css/style.min.css><link rel=preload href=/lib/fontawesome-free/all.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload href=/lib/animate/animate.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Re-parameterization","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"http:\/\/fengchen321.github.io\/posts\/deeplearning\/light-weight\/re-parameterization\/"},"genre":"posts","keywords":"Deep Learning, 轻量级网络","wordcount":2171,"url":"http:\/\/fengchen321.github.io\/posts\/deeplearning\/light-weight\/re-parameterization\/","datePublished":"2023-06-03T18:22:27+08:00","dateModified":"2023-06-03T18:22:27+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"fengchen"},"description":"Re-parameterization"}</script><script src=/js/head/color-scheme.min.js></script></head><body data-header-desktop=sticky data-header-mobile=auto><div class=wrapper data-page-style=normal><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=fengchen><span class=header-title-text>fengchen</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/about/ title=关于本站>关于本站</a></li><li class=menu-item><a class=menu-link href=/posts/>所有文章</a></li><li class=menu-item><a class=menu-link href=/tags/>标签</a></li><li class=menu-item><a class=menu-link href=/categories/>分类</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=fengchen><span class=header-title-text>fengchen</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/about/ title=关于本站>关于本站</a></li><li class=menu-item><a class=menu-link href=/posts/>所有文章</a></li><li class=menu-item><a class=menu-link href=/tags/>标签</a></li><li class=menu-item><a class=menu-link href=/categories/>分类</a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=container><aside class="aside-collection animate__animated animate__fadeIn animate__faster" aria-label=合集></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>Re-Parameterization</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
fengchen</span></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/deep-learning/ class=post-category title="分类 - Deep Learning"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Deep Learning</a></span></div><div class=post-meta-line><span title="发布于 2023-06-03 18:22:27"><i class="fa-solid fa-calendar-days fa-fw me-1" aria-hidden=true></i><time datetime=2023-06-03>2023-06-03</time></span>&nbsp;<span title="2171 字"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 2200 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 5 分钟</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#拓展阅读>拓展阅读</a></li></ul></nav></div></div><div class=content id=content><h2 id=acnet class=heading-element><span>ACNet</span>
<a href=#acnet class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/1908.03930 target=_blank rel="external nofollow noopener noreferrer">ACNet: Strengthening the Kernel Skeletons for Powerful CNN via Asymmetric Convolution Blocks</a></p><p>作者：<a href=https://www.zhihu.com/people/ding-xiao-yi-93 target=_blank rel="external nofollow noopener noreferrer">Xiaohan Ding</a>, Yuchen Guo, Guiguang Ding, Jungong Han</p><p>发表时间：(ICCV 2019)</p><p><a href=https://github.com/DingXiaoH/ACNet target=_blank rel="external nofollow noopener noreferrer">官方源码</a></p></blockquote><p>ACNet，提出了一个Asymmetric Convolution Block (ACB),可以在普通的网络中加入一些ACB来代替普通的卷积，这个仅在训练的时候起作用，然后测试的时候可以使得网络恢复之前的结构，所以这种方法是提升了网络的性能但是完全不会破坏网络。</p><p>Reparam(KxK) = KxK-BN + 1xK-BN + Kx1-BN。这一记法表示用三个平行分支（KxK，1xK，Kx1）的加和来替换一个KxK卷积。注意三个分支各跟一个BN，三个分支分别过BN之后再相加。这样做可以提升卷积网络的性能</p><h2 id=拓展阅读 class=heading-element><span>拓展阅读</span>
<a href=#%e6%8b%93%e5%b1%95%e9%98%85%e8%af%bb class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p><a href=https://zhuanlan.zhihu.com/p/361090497 target=_blank rel="external nofollow noopener noreferrer">结构重参数化：利用参数转换解耦训练和推理结构</a></p><h2 id=acnetv2 class=heading-element><span>ACNetV2</span>
<a href=#acnetv2 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/2103.13425 target=_blank rel="external nofollow noopener noreferrer">Diverse Branch Block: Building a Convolution as an Inception-like Unit</a></p><p>作者：<a href=https://www.zhihu.com/people/ding-xiao-yi-93 target=_blank rel="external nofollow noopener noreferrer">Xiaohan Ding</a>, Xiangyu Zhang, Jungong Han, Guiguang Ding</p><p>发表时间：(CVPR 2021)</p><p><a href=https://github.com/DingXiaoH/DiverseBranchBlock target=_blank rel="external nofollow noopener noreferrer">官方源码</a></p></blockquote><p>Reparam(KxK) = KxK-BN + 1x1-BN + 1x1-BN-AVG-BN + 1x1-BN-KxK-BN。本届CVPR接收的另一篇文章。跟ACNet的相似点在于都是通用的卷积网络基本模块，都可以用来替换常规卷积层。采用了更为复杂的连续卷积（1x1-BN-KxK-BN表示先过1x1卷积，再过BN，再过KxK卷积，再过另一个BN）和average pooling（记作AVG），效果超过ACNet。在这篇文章里也探索了reparam之所以work的原因，给出了一些解释。</p><h2 id=repvgg class=heading-element><span>RepVGG</span>
<a href=#repvgg class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/2101.03697 target=_blank rel="external nofollow noopener noreferrer">RepVGG: Making VGG-style ConvNets Great Again</a></p><p>作者：<a href=https://www.zhihu.com/people/ding-xiao-yi-93 target=_blank rel="external nofollow noopener noreferrer">Xiaohan Ding</a>, <a href="https://scholar.google.com/citations?user=yuB-cfoAAAAJ&amp;hl=zh-CN&amp;oi=sra" target=_blank rel="external nofollow noopener noreferrer">Xiangyu Zhang</a>, <a href="https://scholar.google.com.hk/citations?user=vOAzYlcAAAAJ&amp;hl=zh-CN&amp;oi=ao" target=_blank rel="external nofollow noopener noreferrer">Ningning Ma</a>, Jungong Han, Guiguang Ding, <a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;user=ALVSZAYAAAAJ" target=_blank rel="external nofollow noopener noreferrer">Jian Sun</a></p><p>发表时间：(CVPR 2021)</p><p><a href=https://github.com/DingXiaoH/RepVGG target=_blank rel="external nofollow noopener noreferrer">官方源码</a></p></blockquote><p>RepVGG,RepVGG(Making VGG-style ConvNets Great Again)系列模型是由清华大学(丁贵广团队)、旷视科技(孙剑等人)、港科大和阿伯里斯特威斯大学在 2021 年提出的一个简单但强大的卷积神经网络架构，该架构具有类似于 VGG 的推理时间主体，该主体仅由 3x3 卷积和 ReLU 的堆栈组成，而训练时间模型具有多分支拓扑。训练时间和推理时间架构的这种解耦是通过结构重新参数化(re-parameterization)技术实现的，因此该模型称为 RepVGG。</p><p>Reparam(3x3) = 3x3-BN + 1x1-BN + BN。对每个3x3卷积，在训练时给它构造并行的恒等和1x1卷积分支，并各自过BN后相加。我们简单堆叠这样的结构得到形成了一个VGG式的直筒型架构。推理时的这个架构仅有一路3x3卷积夹ReLU，连分支结构都没有，可以说“一卷到底”，效率很高。这样简单的结构在ImageNet上可以达到超过80%的准确率，比较精度和速度可以超过或打平RegNet等SOTA模型。</p><h2 id=resrep class=heading-element><span>ResRep</span>
<a href=#resrep class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/2007.03260 target=_blank rel="external nofollow noopener noreferrer">ResRep: Lossless CNN Pruning via Decoupling Remembering and Forgetting</a></p><p>作者：<a href=https://www.zhihu.com/people/ding-xiao-yi-93 target=_blank rel="external nofollow noopener noreferrer">Xiaohan Ding</a>, Tianxiang Hao, Jianchao Tan, Ji Liu, Jungong Han, Yuchen Guo, Guiguang Ding</p><p>发表时间：(ICCV 2021)</p><p><a href=https://github.com/DingXiaoH/ResRep target=_blank rel="external nofollow noopener noreferrer">官方源码</a></p></blockquote><p>ResRep: Reparam(KxK) = KxK-BN-1x1。这是一个剪枝（channel pruning）方法。1x1卷积初始化为单位矩阵，因而不改变模型原本的输出。然后我们通过一套特殊设计的更新规则将这个单位矩阵变得行数少于列数（即output_channels&lt;input_channels），然后将整个KxK-BN-1x1序列转换为一个KxK卷积，从而将原本的KxK卷积的output_channels减少。这一方法能在ResNet-50上实现超过50%压缩率的情况下精度完全不掉（从76.15%的torchvision标准模型压缩到还是76.15%），据我所知这是第一个实现如此高无损压缩率的传统（结构化，非动态，非NAS）剪枝方法。</p><h2 id=repmlp class=heading-element><span>RepMLP</span>
<a href=#repmlp class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/2112.11081 target=_blank rel="external nofollow noopener noreferrer">RepMLPNet: Hierarchical Vision MLP with Re-parameterized Locality</a></p><p>作者：<a href=https://www.zhihu.com/people/ding-xiao-yi-93 target=_blank rel="external nofollow noopener noreferrer">Xiaohan Ding</a>, Honghao Chen, Xiangyu Zhang, Jungong Han, Guiguang Ding</p><p>发表时间：(CVPR 2022)</p><p><a href=https://github.com/DingXiaoH/RepMLP target=_blank rel="external nofollow noopener noreferrer">官方源码</a></p></blockquote><p>本文提出了一种将局部性注入 FC 层的重新参数化方法、一种新颖的 MLP 样式块和分层 MLP 架构。 RepMLPNet 在准确性-效率权衡和训练成本方面优于几个同时提出的 MLP。然而，作为 MLP，RepMLPNet 有几个明显的共同弱点。 1) 与 Vision Transformers 类似，MLP 容易过拟合，需要强大的数据增强和正则化技术。 2）在手机等低功耗设备上，MLP 的模型尺寸可能是一个障碍。 3) 虽然我们第一次尝试使用 MLP 骨干进行语义分割的结果很有希望，但我们没有观察到优于传统 CNN 的优势。</p><h2 id=replknet class=heading-element><span>RepLKNet</span>
<a href=#replknet class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/2203.06717 target=_blank rel="external nofollow noopener noreferrer">Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs</a></p><p>作者：<a href=https://www.zhihu.com/people/ding-xiao-yi-93 target=_blank rel="external nofollow noopener noreferrer">Xiaohan Ding</a>, Xiangyu Zhang, Yizhuang Zhou, Jungong Han, Guiguang Ding, Jian Sun</p><p>发表时间：(CVPR 2022)</p><p><a href=https://github.com/DingXiaoH/RepLKNet-pytorch target=_blank rel="external nofollow noopener noreferrer">官方源码</a></p></blockquote><p>这篇论文重新审视了在设计 CNN 架构时长期被忽视的大卷积核。我们证明，使用几个大内核而不是许多小内核可以更有效地产生更大的有效感受野，从而大幅提升 CNN 的性能，尤其是在下游任务上的性能，并在数据和模型扩展时大大缩小 CNN 和 ViT 之间的性能差距.我们希望我们的工作能够推进 CNN 和 ViT 的研究。一方面，对于 CNN 社区，我们的研究结果表明我们应该特别注意 ERF，这可能是高性能的关键。另一方面，对于 ViT 社区，由于大卷积可以替代具有类似行为的多头自注意力，这可能有助于理解自注意力的内在机制</p><h2 id=repghost class=heading-element><span>RepGhost</span>
<a href=#repghost class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/2211.06088 target=_blank rel="external nofollow noopener noreferrer">RepGhost: A Hardware-Efficient Ghost Module via Re-parameterization</a></p><p>作者：Chengpeng Chen, Zichao Guo, Haien Zeng, Pengfei Xiong, Jian Dong</p><p>发表时间：( 2022)</p><p><a href=https://github.com/ChengpengChen/RepGhost target=_blank rel="external nofollow noopener noreferrer">官方源码</a></p></blockquote><p>为了在轻量级 CNN 架构设计中有效地利用特征重用，本文提出了一种新的视角，通过结构重新参数化技术隐式实现特征重用，而不是广泛使用但效率低下的串联操作。通过这种技术，提出了一种用于隐式特征重用的新颖且硬件高效的 RepGhost 模块。所提出的 RepGhost 模块在训练时融合来自不同层的特征，并在推理前在权重空间中执行融合过程，从而产生用于快速推理的简化且硬件高效的架构。基于 RepGhost 模块，我们开发了一个名为 RepGhostNet 的硬件高效轻量级 CNN，它在移动设备的准确性 - 延迟权衡方面展示了多项视觉任务的最新技术水平。</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2023-06-03 18:22:27">更新于 2023-06-03&nbsp;</span></div><div class=post-info-license><span><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 X" data-sharer=twitter data-url=http://fengchen321.github.io/posts/deeplearning/light-weight/re-parameterization/ data-title=Re-Parameterization data-hashtags="Deep Learning,轻量级网络"><i class="fa-brands fa-x-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=http://fengchen321.github.io/posts/deeplearning/light-weight/re-parameterization/ data-hashtag="Deep Learning"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=http://fengchen321.github.io/posts/deeplearning/light-weight/re-parameterization/ data-title=Re-Parameterization><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/deep-learning/ class=post-tag title="标签 - Deep Learning">Deep Learning</a><a href=/tags/%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%BD%91%E7%BB%9C/ class=post-tag title="标签 - 轻量级网络">轻量级网络</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/deeplearning/light-weight/shufflenet/ class=post-nav-item rel=prev title=ShuffleNet><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>ShuffleNet</a><a href=/posts/deeplearning/light-weight/nas/ class=post-nav-item rel=next title=NAS>NAS<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article><aside class=toc id=toc-auto aria-label=目录><h2 class=toc-title>目录&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class="toc-content always-active" id=toc-content-auto></div></aside></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.139.0"><img class=hugo-icon src=/images/hugo.min.svg alt="Hugo logo"> Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.3.15"><img class=fixit-icon src=/images/fixit.min.svg alt="FixIt logo"> FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2024</span><span class=author itemprop=copyrightHolder>
<a href=/>fengchen</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class="variant-numeric d-none">0%</span></div></div><div id=mask></div><div class=reading-progress-bar style=left:0;top:0></div><noscript><div class=noscript-warning>该网站在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=preload href=/lib/katex/katex.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/katex/katex.min.css></noscript><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><script src=/lib/autocomplete/autocomplete.min.js defer></script><script src=/lib/sharer/sharer.min.js async defer></script><script src=/lib/katex/katex.min.js defer></script><script src=/lib/katex/auto-render.min.js defer></script><script src=/lib/katex/copy-tex.min.js defer></script><script src=/lib/katex/mhchem.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.js defer></script><script>window.config={code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:100},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50},version:"v0.3.15"}</script><script src=/js/theme.min.js defer></script></body></html>