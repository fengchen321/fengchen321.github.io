<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>MobileNet - fengchen</title><meta name=author content="fengchen"><meta name=description content="MobileNet"><meta name=keywords content='Deep Learning,轻量级网络'><meta itemprop=name content="MobileNet"><meta itemprop=description content="MobileNet"><meta itemprop=datePublished content="2023-06-03T18:22:27+08:00"><meta itemprop=dateModified content="2023-06-03T18:22:27+08:00"><meta itemprop=wordCount content="5910"><meta itemprop=keywords content="Deep Learning,轻量级网络"><meta property="og:url" content="http://fengchen321.github.io/posts/deeplearning/light-weight/mobilenet/"><meta property="og:site_name" content="fengchen"><meta property="og:title" content="MobileNet"><meta property="og:description" content="MobileNet"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-06-03T18:22:27+08:00"><meta property="article:modified_time" content="2023-06-03T18:22:27+08:00"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="轻量级网络"><meta name=twitter:card content="summary"><meta name=twitter:title content="MobileNet"><meta name=twitter:description content="MobileNet"><meta name=application-name content="FixIt"><meta name=apple-mobile-web-app-title content="FixIt"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical type=text/html href=http://fengchen321.github.io/posts/deeplearning/light-weight/mobilenet/ title="MobileNet - fengchen"><link rel=prev type=text/html href=http://fengchen321.github.io/posts/deeplearning/light-weight/nas/ title=NAS><link rel=next type=text/html href=http://fengchen321.github.io/posts/deeplearning/light-weight/lcnet/ title=LCNet><link rel=alternate type=text/markdown href=http://fengchen321.github.io/posts/deeplearning/light-weight/mobilenet/index.md title="MobileNet - fengchen"><link rel=stylesheet href=/css/style.min.css><link rel=preload href=/lib/fontawesome-free/all.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload href=/lib/animate/animate.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"MobileNet","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"http:\/\/fengchen321.github.io\/posts\/deeplearning\/light-weight\/mobilenet\/"},"genre":"posts","keywords":"Deep Learning, 轻量级网络","wordcount":5910,"url":"http:\/\/fengchen321.github.io\/posts\/deeplearning\/light-weight\/mobilenet\/","datePublished":"2023-06-03T18:22:27+08:00","dateModified":"2023-06-03T18:22:27+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"fengchen"},"description":"MobileNet"}</script><script src=/js/head/color-scheme.min.js></script></head><body data-header-desktop=sticky data-header-mobile=auto><div class=wrapper data-page-style=normal><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=fengchen><span class=header-title-text>fengchen</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/about/ title=关于本站>关于本站</a></li><li class=menu-item><a class=menu-link href=/posts/>所有文章</a></li><li class=menu-item><a class=menu-link href=/tags/>标签</a></li><li class=menu-item><a class=menu-link href=/categories/>分类</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=fengchen><span class=header-title-text>fengchen</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/about/ title=关于本站>关于本站</a></li><li class=menu-item><a class=menu-link href=/posts/>所有文章</a></li><li class=menu-item><a class=menu-link href=/tags/>标签</a></li><li class=menu-item><a class=menu-link href=/categories/>分类</a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=container><aside class="aside-collection animate__animated animate__fadeIn animate__faster" aria-label=合集></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>MobileNet</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
fengchen</span></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/deep-learning/ class=post-category title="分类 - Deep Learning"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Deep Learning</a></span></div><div class=post-meta-line><span title="发布于 2023-06-03 18:22:27"><i class="fa-solid fa-calendar-days fa-fw me-1" aria-hidden=true></i><time datetime=2023-06-03>2023-06-03</time></span>&nbsp;<span title="5910 字"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 6000 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 12 分钟</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#prior-work>Prior Work</a></li><li><a href=#mobilenet-architecture>MobileNet Architecture</a><ul><li><a href=#depthwise-separable-convolution-深度可分离卷积>Depthwise Separable Convolution 深度可分离卷积</a></li><li><a href=#network-structure-and-training>Network Structure and Training</a></li><li><a href=#width-and-resolution-multiplier-宽度alpha-和分辨率-rho超参数>Width and Resolution Multiplier 宽度$\alpha $和分辨率$ \rho$超参数</a></li></ul></li><li><a href=#代码>代码</a></li><li><a href=#扩展阅读>扩展阅读</a></li></ul><ul><li><a href=#preliminaries-discussion-and-intuition>Preliminaries, discussion and intuition</a><ul><li><a href=#depthwise-separable-convolutiondepthwise-separable-convolution-深度可分离卷积>[Depthwise Separable Convolution](###Depthwise Separable Convolution 深度可分离卷积)</a></li><li><a href=#linear-bottleneck>linear bottleneck</a></li><li><a href=#inverted-residuals>Inverted residuals</a></li><li><a href=#information-flow-interpretation>Information flow interpretation</a></li></ul></li><li><a href=#model-architecture>Model Architecture</a></li><li><a href=#experiments>Experiments</a></li><li><a href=#拓展阅读>拓展阅读</a></li></ul><ul><li><ul><li><a href=#efficient-mobile-building-blocks更新block>Efficient Mobile Building Blocks<strong>更新Block</strong></a></li><li><a href=#使用nas搜索参数>使用NAS搜索参数</a></li><li><a href=#redesigning-expensive-layers重新设计耗时层结构>Redesigning Expensive Layers重新设计耗时层结构</a></li></ul></li><li><a href=#mobilenetv3-architecture>MobileNetV3 Architecture</a></li></ul><ul><li><a href=#mobilenext-architecture>MobileNeXt Architecture</a></li></ul><ul><li><a href=#designing-an-expansion-layer>Designing an Expansion Layer</a></li><li><a href=#network-upgrade>Network upgrade</a></li></ul></nav></div></div><div class=content id=content><h2 id=mobilenetv1 class=heading-element><span>MobileNetV1</span>
<a href=#mobilenetv1 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/1704.04861 target=_blank rel="external nofollow noopener noreferrer">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a></p><p>作者：Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam</p><p>发表时间：(CVPR 2017)</p></blockquote><p>MobileNet V1是谷歌2017年提出的轻量化卷积神经网络，用于在移动端、边缘终端设备上进行实时边缘计算和人工智能推理部署。</p><p>使用深度可分离卷积Depthwise Separable Convolution，在保证准确度性能的基础上，将参数量、计算量压缩为标准卷积的八到九分之一。引入网络宽度超参数和输入图像分辨率超参数，进一步控制网络尺寸。</p><p>在ImageNet图像分类、Stanford Dog细粒度图像分类、目标检测、人脸属性识别、人脸编码、以图搜地等计算机视觉任务上，结合知识蒸馏进行评估，MobileNet表现出极致的轻量化和速度性能。</p><h2 id=prior-work class=heading-element><span>Prior Work</span>
<a href=#prior-work class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p><strong>压缩已有模型</strong></p><blockquote><p>知识蒸馏</p><p>权值量化</p><p>剪枝</p><blockquote><p>权重剪枝</p><p>通道剪枝</p></blockquote><p>注意力迁移</p></blockquote><p><strong>直接训练小模型</strong></p><blockquote><p>squeezeNet</p><p>MobileNet</p><p>ShuffleNet</p><p>Xception</p><p>EfficientNet</p><p>NasNet</p><p>DARTS</p></blockquote><p><strong>直接加速卷积运算</strong></p><blockquote><p>im2col+GEMM</p><p>Winograd</p><p><strong>低秩分解</strong></p></blockquote><p><strong>硬件部署</strong></p><blockquote><p>TensorRT</p><p>Jetson</p><p>Tensorflow-slim</p><p>Tensorflow-lite</p><p>Openvino</p></blockquote><h2 id=mobilenet-architecture class=heading-element><span>MobileNet Architecture</span>
<a href=#mobilenet-architecture class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><h3 id=depthwise-separable-convolution-深度可分离卷积 class=heading-element><span>Depthwise Separable Convolution 深度可分离卷积</span>
<a href=#depthwise-separable-convolution-%e6%b7%b1%e5%ba%a6%e5%8f%af%e5%88%86%e7%a6%bb%e5%8d%b7%e7%a7%af class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ul><li><p>将标准卷积分为两部分：<strong>depthwise convolution</strong>，$1\times1$ <strong>pointwise convolution</strong></p><p><strong>逐层卷积处理每个特征通道上的空间信息，逐点卷积进行通道间的特征融合。</strong></p><blockquote><p>标准卷积：卷积核channel=输入特征矩阵channel；输出特征矩阵channel=卷积核个数</p><p>深度可分离卷积：卷积核channel=1；输出特征矩阵channel=卷积核个数=输入特征矩阵channel；</p><p>每个输入通道应用一个卷积核进行逐层卷积</p></blockquote><table border=0><tr><td><img src="/images/Light weight/MobileNet.assets/标准卷积.jpg"></td><td><img src="/images/Light weight/MobileNet.assets/MobileNetV1_depthwise.jpg"></td></tr><tr><td align=center style="color:orange;border-bottom:1px solid #d9d9d9;color:#999;padding:2px">标准卷积</td><td align=center style="color:orange;border-bottom:1px solid #d9d9d9;color:#999;padding:2px">深度可分离卷积</td></tr></table><ul><li>$D_K$：卷积核尺寸；$M$：卷积核通道数（输入通道数）；$N$：卷积核个数（输出通道数）；$D_F$：特征图大小</li><li>标准卷积参数计算：$D_K\times D_K\times M\times N$; 计算量：$D_K\times D_K\times M\times N\times D_F\times D_F$</li><li>深度可分离卷积参数计算：$D_K\times D_K\times M+M\times N$;</li><li>深度可分离卷积计算量：$D_K\times D_K\times M\times D_F\times D_F+M\times N \times D_F \times D_F$</li></ul></li></ul><h3 id=network-structure-and-training class=heading-element><span>Network Structure and Training</span>
<a href=#network-structure-and-training class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><center><img src="/images/Light weight/MobileNet.assets/MobileNetV1_MobileNet Body Architecture.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">MobileNet Body Architecture</div></center><blockquote><p>Filter Shape：卷积核尺寸×输入特征矩阵深度×卷积核个数</p><p>第一层是标准卷积</p><p>放弃pooling层，而使用stride=2的卷积</p><p>所有层后面都有BN层和<strong>ReLU6</strong>；更多的ReLU6，增加了模型的非线性变化，增强了模型的泛化能力。</p><blockquote><p>这个激活函数在float16/int8的嵌入式设备中效果很好，能较好地保持网络的鲁棒性。</p><table border=0><tr><td><img src="/images/Light weight/MobileNet.assets/MobileNetV1_Depthwise Separable Convolution.png"></td><td><img src="/images/Light weight/MobileNet.assets/MobileNetV1_Depthwise Separable Convolution01.jpg"></td></tr><tr><tr><td colspan=2 align=center style="color:orange;border-bottom:1px solid #d9d9d9;color:#999;padding:2px">深度可分离卷积</td></tr></tr></table></blockquote><p>MobileNetV1的大部分计算量和参数量都是$1\times1$卷积花费的。</p><blockquote><center><img src="/images/Light weight/MobileNet.assets/MobileNetV1_计算量和参数分布.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">MobileNetV1的计算量和参数分布</div></center></blockquote></blockquote><h3 id=width-and-resolution-multiplier-宽度alpha-和分辨率-rho超参数 class=heading-element><span>Width and Resolution Multiplier 宽度$\alpha $和分辨率$ \rho$超参数</span>
<a href=#width-and-resolution-multiplier-%e5%ae%bd%e5%ba%a6alpha-%e5%92%8c%e5%88%86%e8%be%a8%e7%8e%87-rho%e8%b6%85%e5%8f%82%e6%95%b0 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p><strong>宽度超参数$\alpha $</strong>：控制卷积层卷积核个数</p><blockquote><p>$D_K\times D_K\times \alpha M\times D_F\times D_F+\alpha M\times \alpha N \times D_F \times D_F$</p><p>$\alpha \in(0,1]$；一般设置为：$1, 0.75,0.5,0.25$</p></blockquote><p><strong>分辨率超参数$\rho $</strong>：控制输入图像大小</p><blockquote><p>$D_K\times D_K\times \alpha M\times \rho D_F\times \rho D_F+\alpha M\times \alpha N \times \rho D_F \times \rho D_F$</p><p>$\rho \in(0,1]$；一般设置为：$1, \frac {6}{7},\frac {5}{7},\frac {4}{7}$ 对应分辨率为$224,192,160,128$</p></blockquote><p>计算举例：$D_K=3,M=512,N=512,D_F=14$</p><table border=0><tr><td><img src="/images/Light weight/MobileNet.assets/MobileNetV1_例子.png"></td><td><img src="/images/Light weight/MobileNet.assets/MobileNetV1_例子0.png"></td></tr><tr><td colspan=2 align=center style="color:orange;border-bottom:1px solid #d9d9d9;color:#999;padding:2px">MobileNetV1的计算例子</td></tr></table>深度卷积在GPU上运行速度还不如一般的标准卷积，因为depthwise 的卷积核复用率比普通卷积要小很多，计算和内存访问的比值比普通卷积更小，因此会花更多时间在内存开销上，而且per-channel的矩阵计算很小不容易并行导致的更慢，但理论上计算量和参数量都是大大减少的，只是底层优化的问题。<h2 id=代码 class=heading-element><span>代码</span>
<a href=#%e4%bb%a3%e7%a0%81 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>MobileNet</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>num_classes</span><span class=o>=</span><span class=mi>1000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>MobileNet</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>num_classes</span> <span class=o>=</span> <span class=n>num_classes</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>def</span> <span class=nf>conv_bn</span><span class=p>(</span><span class=n>inp</span><span class=p>,</span> <span class=n>oup</span><span class=p>,</span> <span class=n>stride</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>inp</span><span class=p>,</span> <span class=n>oup</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>oup</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(</span><span class=n>inplace</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>def</span> <span class=nf>conv_dw</span><span class=p>(</span><span class=n>inp</span><span class=p>,</span> <span class=n>oup</span><span class=p>,</span> <span class=n>stride</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>inp</span><span class=p>,</span> <span class=n>inp</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>groups</span><span class=o>=</span><span class=n>inp</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>inp</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(</span><span class=n>inplace</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>inp</span><span class=p>,</span> <span class=n>oup</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>oup</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(</span><span class=n>inplace</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>conv_bn</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>2</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>conv_dw</span><span class=p>(</span><span class=mi>32</span><span class=p>,</span> <span class=mi>64</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>conv_dw</span><span class=p>(</span><span class=mi>64</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>2</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>conv_dw</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=mi>128</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>conv_dw</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>2</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>conv_dw</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>256</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>conv_dw</span><span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>512</span><span class=p>,</span> <span class=mi>2</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>conv_dw</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>512</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>conv_dw</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>512</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>conv_dw</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>512</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>conv_dw</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>512</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>conv_dw</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>512</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>conv_dw</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>1024</span><span class=p>,</span> <span class=mi>2</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>conv_dw</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>1024</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>AvgPool2d</span><span class=p>(</span><span class=mi>7</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>num_classes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span></span></span></code></pre></td></tr></table></div></div><h2 id=扩展阅读 class=heading-element><span>扩展阅读</span>
<a href=#%e6%89%a9%e5%b1%95%e9%98%85%e8%af%bb class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p><a href=https://keras.io/api/applications/mobilenet/ target=_blank rel="external nofollow noopener noreferrer">Keras中的MobileNet预训练模型文档</a></p><p><a href=https://github.com/keras-team/keras/blob/master/keras/applications/mobilenet.py target=_blank rel="external nofollow noopener noreferrer">Keras中的MobileNet预训练模型代码</a></p><p><a href="https://link.zhihu.com/?target=http%3A//www.cmapx.polytechnique.fr/~sifre/research/phd_sifre.pdf" target=_blank rel="external nofollow noopener noreferrer">Laurent Sifre2013博士论文：Rigid-motion scattering for image classification</a>]</p><p><a href=https://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-93.pdf target=_blank rel="external nofollow noopener noreferrer">贾扬清博士论文</a></p><p><a href=https://www.zhihu.com/question/343343895 target=_blank rel="external nofollow noopener noreferrer">为什么 MobileNet、ShuffleNet 在理论上速度很快，工程上并没有特别大的提升？</a></p><p><a href=https://zhuanlan.zhihu.com/p/70703846 target=_blank rel="external nofollow noopener noreferrer">轻量级神经网络“巡礼”（二）—— MobileNet，从V1到V3</a></p><p><a href=https://medium.com/@yu4u/why-mobilenet-and-its-variants-e-g-shufflenet-are-fast-1c7048b9618d target=_blank rel="external nofollow noopener noreferrer">Why MobileNet and Its Variants (e.g. ShuffleNet) Are Fast</a></p><p><a href=https://yinguobing.com/separable-convolution/#fn2 target=_blank rel="external nofollow noopener noreferrer">卷积神经网络中的Separable Convolution</a></p><p><a href=https://machinethink.net/blog/googles-mobile-net-architecture-on-iphone/ target=_blank rel="external nofollow noopener noreferrer">Google’s MobileNets on the iPhone</a></p><h2 id=mobilenetv2 class=heading-element><span>MobileNetV2</span>
<a href=#mobilenetv2 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/1801.04381 target=_blank rel="external nofollow noopener noreferrer">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></p><p>作者：Mark Sandler， Andrew Howard ，<a href=http://dreamdragon.github.io/ target=_blank rel="external nofollow noopener noreferrer">Menglong Zhu</a> ，Andrey Zhmoginov， Liang-Chieh Chen</p><p>发表时间：(CVPR 2018)</p></blockquote><h2 id=preliminaries-discussion-and-intuition class=heading-element><span>Preliminaries, discussion and intuition</span>
<a href=#preliminaries-discussion-and-intuition class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><h3 id=depthwise-separable-convolutiondepthwise-separable-convolution-深度可分离卷积 class=heading-element><span>[Depthwise Separable Convolution](###Depthwise Separable Convolution 深度可分离卷积)</span>
<a href=#depthwise-separable-convolutiondepthwise-separable-convolution-%e6%b7%b1%e5%ba%a6%e5%8f%af%e5%88%86%e7%a6%bb%e5%8d%b7%e7%a7%af class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><h3 id=linear-bottleneck class=heading-element><span>linear bottleneck</span>
<a href=#linear-bottleneck class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><center><img src="/images/Light weight/MobileNet.assets/MobileNetV2_MobileNetV1.svg"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">MobileNetV2_MobileNetV1</div></center><center><img src="/images/Light weight/MobileNet.assets/MobileNetV2_Depthwise Separable Convolution.jpg"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">MobileNetV2微结构</div></center><p>第一层Pointwise convolution：目的是在数据进入深度卷积之前扩展数据中的通道数</p><blockquote><p>Depthwise convolution的Filter数量取决于之前的Pointwise的通道数。而这个通道数是可以任意指定的，因此解除了3x3卷积核个数的限制</p></blockquote><p>第二次Pointwise则不采用非线性激活，保留线性特征</p><blockquote><ol><li><p>If the manifold of interest remains non-zero volume after ReLU transformation, it corresponds to a linear transformation.</p></li><li><p>ReLU is capable of preserving complete information about the input manifold, but only if the input manifold lies in a low-dimensional subspace of the input space.</p></li></ol><p>ReLU激活函数对低维特征信息造成大量损失。</p></blockquote><h3 id=inverted-residuals class=heading-element><span>Inverted residuals</span>
<a href=#inverted-residuals class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><center><img src="/images/Light weight/MobileNet.assets/MobileNetV2_bottleneck.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Inverted residuals</div></center><blockquote><p>灰色为下一个结构的开始；有格子阴影的层：表示不包含非线性的层</p><p>The diagonally hatched texture indicates layers that do not contain non-linearities.</p></blockquote><center><img src="/images/Light weight/MobileNet.assets/MobileNetV2_ResNet.svg"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">MobileNetV2_ResNet</div></center><center><img src="/images/Light weight/MobileNet.assets/MobileNetV2_ExpandProject.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">MobileNetV2_ExpandProject</div></center><p>ResNet 先降维 (0.25倍)、卷积、再升维，而 MobileNet V2 则是 先升维 (6倍)、卷积、再降维。</p><h3 id=information-flow-interpretation class=heading-element><span>Information flow interpretation</span>
<a href=#information-flow-interpretation class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><center><img src="/images/Light weight/MobileNet.assets/MobileNetV2_Information flow interpretation.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">compress</div></center><p>扩展层充当解压缩器（如<code>unzip</code>），首先将数据恢复为完整形式，然后深度层执行网络此阶段重要的任何过滤，最后投影层压缩数据以使其再次变小。</p><h2 id=model-architecture class=heading-element><span>Model Architecture</span>
<a href=#model-architecture class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><center><img src="/images/Light weight/MobileNet.assets/MobileNetV2_MobileNet Body Architecture.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">MobileNetV2 Architecture</div></center><blockquote><p>t：expansion rate；c：卷积核个数；n：重复次数；s：首个模块的步长，其他为1</p></blockquote><h2 id=experiments class=heading-element><span>Experiments</span>
<a href=#experiments class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><center><img src="/images/Light weight/MobileNet.assets/MobileNetV2_Classifier.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Classifier</div></center><p>基础网络的输出通常是 7×7 像素的图像。分类器首先使用<strong>全局池化层</strong>将大小从 7×7 减小到 1×1 像素——基本上采用 49 个不同预测器的集合——然后是分类层和 softmax。</p><center><img src="/images/Light weight/MobileNet.assets/MobileNetV2_SSD.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Object Detection</div></center><p>获取最后一个基础网络层的输出，还获取前几个层的输出，并将这些输出送到 SSD 层。MobileNet 层的工作是将输入图像中的像素转换为描述图像内容的<strong>特征</strong>，并将这些<strong>特征</strong>传递给其他层。因此，此处使用 MobileNet 作为第二个神经网络的<strong>特征提取器</strong>。</p><h2 id=拓展阅读 class=heading-element><span>拓展阅读</span>
<a href=#%e6%8b%93%e5%b1%95%e9%98%85%e8%af%bb class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p><a href=https://github.com/keras-team/keras/blob/master/keras/applications/mobilenet_v2.py target=_blank rel="external nofollow noopener noreferrer">Keras预训练MobileNetV2源代码</a></p><p><a href=https://awesomeopensource.com/projects/mobilenetv2 target=_blank rel="external nofollow noopener noreferrer">与MobileNetV2有关的Github高赞开源项目</a></p><p><a href=https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html target=_blank rel="external nofollow noopener noreferrer">谷歌AI博客</a></p><p><a href=https://www.researchgate.net/figure/MobileNetV2-with-inverted-residuals-Process-for-making-linear-bottlenecks-with-the_fig2_346607345 target=_blank rel="external nofollow noopener noreferrer">Figure 2: MobileNetV2 with inverted residuals</a></p><p><a href=https://yinguobing.com/bottlenecks-block-in-mobilenetv2/ target=_blank rel="external nofollow noopener noreferrer">图解MobileNetV2中的Bottlenecks</a></p><p><a href=https://zhuanlan.zhihu.com/p/33075914 target=_blank rel="external nofollow noopener noreferrer">知乎：MobileNet V2 论文初读</a></p><p><a href=https://machinethink.net/blog/mobilenet-v2/ target=_blank rel="external nofollow noopener noreferrer">MobileNet version 2</a></p><h2 id=mobilenetv3 class=heading-element><span>MobileNetV3</span>
<a href=#mobilenetv3 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/1905.02244 target=_blank rel="external nofollow noopener noreferrer">Searching for MobileNetV3</a></p><p>作者：Andrew Howard，Mark Sandler，Grace Chu，Liang-Chieh Chen，Bo Chen， Mingxing Tan，Weijun Wang，Yukun Zhu， Ruoming Pang， Vijay Vasudevan， Quoc V. Le， Hartwig Adam</p><p>发表时间：(CVPR 2019)</p></blockquote><h3 id=efficient-mobile-building-blocks更新block class=heading-element><span>Efficient Mobile Building Blocks<strong>更新Block</strong></span>
<a href=#efficient-mobile-building-blocks%e6%9b%b4%e6%96%b0block class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><center><img src="/images/Light weight/MobileNet.assets/MobileNetV3_block.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">MobileNetV3_block</div></center><ul><li>加入SE模块(Squeeze-and-Excite)：SE模块是一种轻量级的通道注意力模块。depthwise之后，经过池化层，然后第一个fc层，通道数缩小4倍，再经过第二个fc层，通道数变换回去（扩大4倍），然后与depthwise进行按位相乘。</li></ul><center><img src="/images/Light weight/MobileNet.assets/MobileNetV3_block_SE.png" height=300 width=600><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">MobileNetV3_block_SE</div></center><ul><li>更新激活函数</li></ul><h3 id=使用nas搜索参数 class=heading-element><span>使用NAS搜索参数</span>
<a href=#%e4%bd%bf%e7%94%a8nas%e6%90%9c%e7%b4%a2%e5%8f%82%e6%95%b0 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>利用NAS（神经结构搜索）和<a href=https://arxiv.org/abs/1804.03230 target=_blank rel="external nofollow noopener noreferrer">NetAdapt</a>来搜索网络的配置和参数。</p><h3 id=redesigning-expensive-layers重新设计耗时层结构 class=heading-element><span>Redesigning Expensive Layers重新设计耗时层结构</span>
<a href=#redesigning-expensive-layers%e9%87%8d%e6%96%b0%e8%ae%be%e8%ae%a1%e8%80%97%e6%97%b6%e5%b1%82%e7%bb%93%e6%9e%84 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><center><img src="/images/Light weight/MobileNet.assets/MobileNetV3_1.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">MobileNetV3_Last stage</div></center><blockquote><p><strong>减少第一个卷积层的卷积核个数(32->16)</strong>：使用ReLU或者swish激活函数，能将通道数缩减到16维，且准确率保持不变。这又能节省2ms的延时。</p></blockquote>$$
ReLU6(x)=min(max(x,0),6)\\
h\_sigmoid[x]=\frac{ReLU6(x+3)}{6}
$$<blockquote><p>$swish\ x = x\dot \sigma (x)$ ；$\sigma = \frac{1}{1+e^{-x}}$ 计算、求导复杂，对量化过程不友好。将sigmoid函数替换为piece-wise linear hard analog function.</p>$$
h\_swish[x]=x\frac{ReLU6(x+3)}{6}
$$<p><strong>精简Last Stage</strong> ：Original Last Stage为v2的最后输出几层，v3版本将平均池化层提前了。在使用1×1卷积进行扩张后，就紧接池化层-激活函数，最后使用1×1的卷积进行输出。通过这一改变，能减少7ms的延迟，提高了11%的运算速度，且几乎没有任何精度损失。</p></blockquote><h2 id=mobilenetv3-architecture class=heading-element><span>MobileNetV3 Architecture</span>
<a href=#mobilenetv3-architecture class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><table border=0><tr><td align=center><img src="/images/Light weight/MobileNet.assets/MobileNetV3_Large.png"></td><td align=center><img src="/images/Light weight/MobileNet.assets/MobileNetV3_Small.png"></td></tr><tr><td align=center style="color:orange;border-bottom:1px solid #d9d9d9;color:#999;padding:2px">Specification for MobileNetV3-Large</td><td align=center style="color:orange;border-bottom:1px solid #d9d9d9;color:#999;padding:2px">Specification for MobileNetV3-Small</td></tr></table><blockquote><p>exo_size：升维；#out 输出通道数； NL：激活函数 ； s：步距 ；NBN：没有批量归一化</p></blockquote><h2 id=mobilenext class=heading-element><span>MobileNeXt</span>
<a href=#mobilenext class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/2007.02269 target=_blank rel="external nofollow noopener noreferrer">Rethinking Bottleneck Structure for Efficient Mobile Network Design</a></p><p>作者：Zhou Daquan, Qibin Hou, Yunpeng Chen, Jiashi Feng, Shuicheng Yan</p><p>发表时间：(ECCV 2020)</p><p><a href=https://github.com/zhoudaquan/rethinking_bottleneck_design target=_blank rel="external nofollow noopener noreferrer">官方代码</a></p><p><a href=https://github.com/Andrew-Qibin/ssdlite-pytorch-mobilenext/blob/master/ssd/modeling/backbone/mobilenext.py target=_blank rel="external nofollow noopener noreferrer">code</a></p></blockquote><center><img src="/images/Light weight/MobileNet.assets/MobileNeXt_0.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">block</div></center><blockquote><p>每个块的厚度来表示相应的相对通道数</p></blockquote><p><strong>(a)：Classic residual bottleneck blocks 经典残差块</strong></p><blockquote><p>一个 1×1 卷积用于通道缩减，一个 3×3 卷积用于空间特征提取，另一个 1×1 卷积用于通道扩展</p></blockquote><p><strong>(b)：Inverted residual blocks 倒残差块</strong></p><blockquote><p>一个 1×1 卷积用于通道扩展，一个 3×3 深度可分离卷积用于空间特征提取，另一个 1×1 卷积用于通道缩减</p><blockquote><p>将低维压缩张量作为输入，并通过逐点卷积将其扩展到更高维。应用深度卷积进行空间上下文编码，另一个逐点卷积以生成低维特征张量作为下一个块的输入。</p><p>由于相邻倒置差之间的表示是低维的。bottleneck之间的shortcut可能会阻止来自顶层的梯度在模型训练期间成功传播到底层。</p><p>深度可分离卷积用于空间特征提取后进行通道压缩可能无法保留足够的有用信息，造成信息丢失</p></blockquote><p>ShuffleNetV2 在反向残差块之前插入一个通道拆分模块，并在其后添加另一个通道混洗模块</p><p>HBONet 中，下采样操作被引入到倒残差块中，用于对更丰富的空间信息进行建模。</p><p>MobileNetV3 提出在每个阶段搜索最优激活函数和倒残差块的扩展率</p><p>MixNet 提出在倒残差块中搜索深度可分离卷积的最佳内核大小</p></blockquote><p><strong>(c)：Sandglass Block 沙漏块</strong></p><p>在更高维度上执行恒等映射和空间变换，从而有效地减轻信息丢失和梯度混淆</p><center><img src="/images/Light weight/MobileNet.assets/MobileNeXt_different_variants.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">MobileNeXt_different_variants</div></center><center><img src="/images/Light weight/MobileNet.assets/MobileNeXt_different_variants_1.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Performance of different variants</div></center><p>(a)：直接修改经典的残差块构建的，将标准的 3×3 卷积替换为 3×3 深度卷积。</p><blockquote><p>与(d)相比，性能下降了约 5%：可能由于深度卷积是在具有低维特征空间的bottleneck中进行的，因此无法捕获足够的空间信息。</p></blockquote><p>(b)：在a基础上添加加了另一个 3×3 深度卷积</p><blockquote><p>与(a)相比 精度提高了 1% 以上：表明编码更多的空间信息确实有帮助</p><p>与(d)相比</p></blockquote><p>(c)：基于原始的倒残差块，将深度卷积从高维特征空间移动到特征通道较少的bottleneck位置</p><blockquote><p>与(b)相比更差：表明在高维表示之间建立shortcut更有利于网络性能</p></blockquote><p><strong>(d)：沙漏块</strong></p><blockquote><p>设计原则</p><ul><li><p>为了在传输到顶层时保留来自底层的更多信息并促进跨层的梯度传播，应该在高维表示之间建立shortcut</p></li><li><p>具有小内核大小（例如 3 × 3）的深度卷积是轻量级的，可以适当地将几个深度卷积应用于更高维的特征，以便可以编码更丰富的空间信息。</p></li></ul></blockquote><p>将bottleneck保持在剩余路径的中间，以节省参数和计算成本。</p><p>高维表示之间建立shortcut。</p><p>两个深度卷积都是在高维空间中进行的，可以提取更丰富的特征表示。</p><p>使用线性瓶颈可以帮助防止特征值被归零，从而减少信息丢失：第一个逐点卷积之后不添加任何激活层。</p><p>仅在第一个深度卷积层和最后一个逐点卷积层之后添加激活层：最后一个卷积之后添加一个激活层会对分类性能产生负面影响（经验）。</p><center><img src="/images/Light weight/MobileNet.assets/MobileNeXt_sandglass_block.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">MobileNeXt_sandglass_block</div></center><p>注意，$M\neq N$时不添加shortcut</p><h2 id=mobilenext-architecture class=heading-element><span>MobileNeXt Architecture</span>
<a href=#mobilenext-architecture class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><table border=0><tr><td align=center><img src="/images/Light weight/MobileNet.assets/MobileNetV2_MobileNet Body Architecture.png"></td><td align=center><img src="/images/Light weight/MobileNet.assets/MobileNeXt.png"></td></tr><tr><td align=center style="color:orange;border-bottom:1px solid #d9d9d9;color:#999;padding:2px">MobileNetV2</td><td align=center style="color:orange;border-bottom:1px solid #d9d9d9;color:#999;padding:2px">MobileNeXt</td></tr></table><blockquote><p>b：重复次数。</p><p>t：通道扩展比。</p><p>k：类别</p></blockquote><p>为了证明模型的好处来自于新颖架构，而不是利用更多的深度卷积或更大的感受野</p><blockquote><p>与 MobileNetV2 的改进版本进行比较，在中间插入了一个深度卷积块。MobileNetV2 的性能提高到了 73%，这仍然比MobileNeXt的 (74%) 差得多。</p></blockquote>$$
G_{1：\alpha M}= φ(F)_{1：\alpha M} + F_{1：\alpha M}, \ G_{\alpha M:M} = φ(F)_{\alpha M:M}
$$<blockquote><p>首先，在减少乘数之后，可以减少每个构建块中的element-wise additions的数量。逐元素加法非常耗时。可以选择较低的恒等张量乘数以产生更好的延迟，而性能几乎没有下降。</p><p>其次，可以减少内存访问次数。减少恒等张量的通道维度可以有效地鼓励处理器将其存储在缓存或处理器附近的其他更快的内存中，从而改善延迟。</p></blockquote><h2 id=rexnet class=heading-element><span>ReXNet</span>
<a href=#rexnet class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/2007.00992 target=_blank rel="external nofollow noopener noreferrer">Rethinking Channel Dimensions for Efficient Model Design</a></p><p>作者：Dongyoon Han, Sangdoo Yun, Byeongho Heo, YoungJoon Yoo</p><p>发表时间：(CVPR 2021)</p><p>v1版本叫做<a href=https://arxiv.org/abs/2007.00992v1 target=_blank rel="external nofollow noopener noreferrer">ReXNet: Diminishing Representational Bottleneck on Convolutional Neural Network</a></p><p><a href=https://github.com/clovaai/rexnet target=_blank rel="external nofollow noopener noreferrer">官方代码</a></p></blockquote><p>ReXNet,ReXNet 是 NAVER 集团 ClovaAI 研发中心基于一种网络架构设计新范式而构建的网络。针对现有网络中存在的 Representational Bottleneck 问题，作者提出了一组新的设计原则。作者认为传统的网络架构设计范式会产生表达瓶颈，进而影响模型的性能。为研究此问题，作者研究了上万个随机网络生成特征的 matric rank，同时进一步研究了网络层中通道配置方案。基于此，作者提出了一组简单而有效的设计原则，以消除表达瓶颈问题。</p><h2 id=designing-an-expansion-layer class=heading-element><span>Designing an Expansion Layer</span>
<a href=#designing-an-expansion-layer class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><center><img src="/images/Light weight/MobileNet.assets/ReXNet_rank_ratio.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Visualization of the output rank</div></center><blockquote><p>在第一个1×1卷积时，需要用6或更小的扩展比来设计一个inverted bottleneck；</p><p>在轻量级模型中，每个带有深度卷积的inverted bottleneck都需要更高的通道维度比；</p><p>复杂的非线性，如ELU和SiLU，需要放在1×1卷积或3×3卷积之后（不是深度卷积）</p><p>channel dimension ratio：$d_{in}/d_{out}\in[0.1,1]$</p><p>rank ratio：$rank(f(WX))/d_{out}$</p><blockquote><p>$f(WX)$：输出特征；$W\in R^{d_{out}\times d_{in}};X\in R^{d_{in}\times N}$；$N$为batchsize；$f$为归一化后的非线性函数</p></blockquote><p>Average Rank Ratio:每个模型取平均</p></blockquote><center><img src="/images/Light weight/MobileNet.assets/ReXNet_block_index.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Visualization of the searched models’ channel dimensions vs. block index</div></center><center><img src="/images/Light weight/MobileNet.assets/ReXNet_channel_config.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Detailed searched channel configurations</div></center><blockquote><p>从200个搜索过的模型中收集前10%、中间10%（即前50%和60%之间的模型）和后10%的模型 Red: top-10%; blue: middle-10%; green: bottom-10% accuracy models</p><p>红色的Block Index的线性参数化享有更高的精度，同时保持类似的计算成本。最佳模型的通道配置为线性增加。</p><p>绿色的模型大幅减少了输入侧的通道，因此，大部分的权重参数被放置在输出侧，导致精度的损失。</p><p>蓝色代表处于中间10%精度的模型，与传统通道配置相似。传统配置是通过限制早期层的通道，并在靠近输出的地方提供更多的通道来达到flop-efficienty的目的。</p></blockquote><h2 id=network-upgrade class=heading-element><span>Network upgrade</span>
<a href=#network-upgrade class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><table border=0><tr><td align=center><img src="/images/Light weight/MobileNet.assets/MobileNetV2_MobileNet Body Architecture.png"></td><td align=center><img src="/images/Light weight/MobileNet.assets/ReXNet_1.0x.png"></td></tr><tr><td align=center style="color:orange;border-bottom:1px solid #d9d9d9;color:#999;padding:2px">MobileNetv2</td><td align=center style="color:orange;border-bottom:1px solid #d9d9d9;color:#999;padding:2px">ReXNet_1.0x</td></tr></table><table border=0><tr><td align=center><img src="/images/Light weight/MobileNet.assets/MobileNetV1_MobileNet Body Architecture.png"></td><td align=center><img src="/images/Light weight/MobileNet.assets/ReXNet_plain.png"></td></tr><tr><td align=center style="color:orange;border-bottom:1px solid #d9d9d9;color:#999;padding:2px">MobileNetv1</td><td align=center style="color:orange;border-bottom:1px solid #d9d9d9;color:#999;padding:2px">ReXNet_plain</td></tr></table><center><img src="/images/Light weight/MobileNet.assets/ReXNet.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">ReXNet</div></center><p><strong>通道数线性增加</strong></p><p>在每个倒置瓶颈的第一个1×1卷积后替换ReLU6</p><blockquote><p>观察到维数比较小的层需要更多的处理</p></blockquote><p>第二个深度卷积的通道维数比为1，所以在此不替换ReLU6。</p><p>MB1和MB6指的是MobileNetV2的inverted bottleneck，扩展率分别为1和6。</p><p><a href=https://zhuanlan.zhihu.com/p/155504072 target=_blank rel="external nofollow noopener noreferrer">ReXNet｜消除表达瓶颈，提升性能指标</a></p><h2 id=mixnet class=heading-element><span>MixNet</span>
<a href=#mixnet class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/1907.09595v3 target=_blank rel="external nofollow noopener noreferrer">MixConv: Mixed Depthwise Convolutional Kernels</a></p><p>作者：Mingxing Tan, Quoc V. Le</p><p>发表时间：(BMVC 2019)</p></blockquote><p>MixConv,MixNet 是谷歌出的一篇关于轻量级网络的文章，主要工作就在于探索不同大小的卷积核的组合。作者发现目前网络有以下两个问题：小的卷积核感受野小，参数少，但是准确率不高;大的卷积核感受野大，准确率相对略高，但是参数也相对增加了很多.为了解决上面两个问题，文中提出一种新的混合深度分离卷积(MDConv)(mixed depthwise convolution)，将不同的核大小混合在一个卷积运算中，并且基于 AutoML 的搜索空间，提出了一系列的网络叫做 MixNets，在 ImageNet 上取得了较好的效果。</p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2023-06-03 18:22:27">更新于 2023-06-03&nbsp;</span></div><div class=post-info-license><span><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 X" data-sharer=twitter data-url=http://fengchen321.github.io/posts/deeplearning/light-weight/mobilenet/ data-title=MobileNet data-hashtags="Deep Learning,轻量级网络"><i class="fa-brands fa-x-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=http://fengchen321.github.io/posts/deeplearning/light-weight/mobilenet/ data-hashtag="Deep Learning"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=http://fengchen321.github.io/posts/deeplearning/light-weight/mobilenet/ data-title=MobileNet><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/deep-learning/ class=post-tag title="标签 - Deep Learning">Deep Learning</a><a href=/tags/%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%BD%91%E7%BB%9C/ class=post-tag title="标签 - 轻量级网络">轻量级网络</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/deeplearning/light-weight/nas/ class=post-nav-item rel=prev title=NAS><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>NAS</a><a href=/posts/deeplearning/light-weight/lcnet/ class=post-nav-item rel=next title=LCNet>LCNet<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article><aside class=toc id=toc-auto aria-label=目录><h2 class=toc-title>目录&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class="toc-content always-active" id=toc-content-auto></div></aside></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.139.0"><img class=hugo-icon src=/images/hugo.min.svg alt="Hugo logo"> Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.3.15"><img class=fixit-icon src=/images/fixit.min.svg alt="FixIt logo"> FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2024 - 2025</span><span class=author itemprop=copyrightHolder>
<a href=/>fengchen</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class="variant-numeric d-none">0%</span></div></div><div id=mask></div><div class=reading-progress-bar style=left:0;top:0></div><noscript><div class=noscript-warning>该网站在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=preload href=/lib/katex/katex.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/katex/katex.min.css></noscript><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><script src=/lib/autocomplete/autocomplete.min.js defer></script><script src=/lib/sharer/sharer.min.js async defer></script><script src=/lib/katex/katex.min.js defer></script><script src=/lib/katex/auto-render.min.js defer></script><script src=/lib/katex/copy-tex.min.js defer></script><script src=/lib/katex/mhchem.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.js defer></script><script>window.config={code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:100},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50},version:"v0.3.15"}</script><script src=/js/theme.min.js defer></script></body></html>