<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>ConvNeXt - fengchen</title><meta name=author content="fengchen"><meta name=description content="ConvNeXt"><meta name=keywords content='Deep Learning,图像分类模型'><meta itemprop=name content="ConvNeXt"><meta itemprop=description content="ConvNeXt"><meta itemprop=datePublished content="2023-06-02T18:22:27+08:00"><meta itemprop=dateModified content="2023-06-02T18:22:27+08:00"><meta itemprop=wordCount content="1674"><meta itemprop=keywords content="Deep Learning,图像分类模型"><meta property="og:url" content="http://fengchen321.github.io/posts/deeplearning/image-classification/convnext-/"><meta property="og:site_name" content="fengchen"><meta property="og:title" content="ConvNeXt"><meta property="og:description" content="ConvNeXt"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-06-02T18:22:27+08:00"><meta property="article:modified_time" content="2023-06-02T18:22:27+08:00"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="图像分类模型"><meta name=twitter:card content="summary"><meta name=twitter:title content="ConvNeXt"><meta name=twitter:description content="ConvNeXt"><meta name=application-name content="FixIt"><meta name=apple-mobile-web-app-title content="FixIt"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical type=text/html href=http://fengchen321.github.io/posts/deeplearning/image-classification/convnext-/ title="ConvNeXt - fengchen"><link rel=prev type=text/html href=http://fengchen321.github.io/posts/deeplearning/image-classification/efficientnet/ title=EfficientNet><link rel=next type=text/html href=http://fengchen321.github.io/posts/deeplearning/image-classification/automl/ title=AutoML><link rel=alternate type=text/markdown href=http://fengchen321.github.io/posts/deeplearning/image-classification/convnext-/index.md title="ConvNeXt - fengchen"><link rel=stylesheet href=/css/style.min.css><link rel=preload href=/lib/fontawesome-free/all.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload href=/lib/animate/animate.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"ConvNeXt","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"http:\/\/fengchen321.github.io\/posts\/deeplearning\/image-classification\/convnext-\/"},"genre":"posts","keywords":"Deep Learning, 图像分类模型","wordcount":1674,"url":"http:\/\/fengchen321.github.io\/posts\/deeplearning\/image-classification\/convnext-\/","datePublished":"2023-06-02T18:22:27+08:00","dateModified":"2023-06-02T18:22:27+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"fengchen"},"description":"ConvNeXt"}</script><script src=/js/head/color-scheme.min.js></script></head><body data-header-desktop=sticky data-header-mobile=auto><div class=wrapper data-page-style=normal><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=fengchen><span class=header-title-text>fengchen</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/about/ title=关于本站>关于本站</a></li><li class=menu-item><a class=menu-link href=/posts/>所有文章</a></li><li class=menu-item><a class=menu-link href=/tags/>标签</a></li><li class=menu-item><a class=menu-link href=/categories/>分类</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=fengchen><span class=header-title-text>fengchen</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/about/ title=关于本站>关于本站</a></li><li class=menu-item><a class=menu-link href=/posts/>所有文章</a></li><li class=menu-item><a class=menu-link href=/tags/>标签</a></li><li class=menu-item><a class=menu-link href=/categories/>分类</a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=container><aside class="aside-collection animate__animated animate__fadeIn animate__faster" aria-label=合集></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>ConvNeXt</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
fengchen</span></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/deep-learning/ class=post-category title="分类 - Deep Learning"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Deep Learning</a></span></div><div class=post-meta-line><span title="发布于 2023-06-02 18:22:27"><i class="fa-solid fa-calendar-days fa-fw me-1" aria-hidden=true></i><time datetime=2023-06-02>2023-06-02</time></span>&nbsp;<span title="1674 字"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 1700 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 4 分钟</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#modernizing-a-convnet-a-roadmap路线图>Modernizing a ConvNet: a Roadmap路线图</a><ul><li><a href=#detailed-architectures>Detailed Architectures</a></li><li><a href=#macro-design-宏观设计>macro design 宏观设计</a></li><li><a href=#resnext-794---805>ResNeXt (79.4%&mdash;>80.5%)</a></li><li><a href=#inverted-bottleneck--805---806>Inverted bottleneck (80.5%&mdash;>80.6%)</a></li><li><a href=#large-kernel-size>large kernel size</a></li><li><a href=#various-layer-wise-micro-designs各种层级的微观设计>various layer-wise micro designs各种层级的微观设计</a></li></ul></li><li><a href=#empirical-evaluations-on-imagenet>Empirical Evaluations on ImageNet</a><ul><li><a href=#convnext-变体配置>ConvNeXt 变体配置</a></li><li><a href=#training-techniques>Training Techniques</a></li></ul></li><li><a href=#拓展阅读>拓展阅读</a></li></ul></nav></div></div><div class=content id=content><h2 id=convnext class=heading-element><span>ConvNeXt</span>
<a href=#convnext class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/2201.03545v1 target=_blank rel="external nofollow noopener noreferrer">A ConvNet for the 2020s</a>
作者：<a href=https://liuzhuang13.github.io/ target=_blank rel="external nofollow noopener noreferrer">Zhuang Liu</a>, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie</p><p>发表时间：2022</p><p><a href=https://github.com/facebookresearch/ConvNeXt target=_blank rel="external nofollow noopener noreferrer">Official Code</a></p><p>ResNet的Transformer版</p></blockquote><h2 id=modernizing-a-convnet-a-roadmap路线图 class=heading-element><span>Modernizing a ConvNet: a Roadmap路线图</span>
<a href=#modernizing-a-convnet-a-roadmap%e8%b7%af%e7%ba%bf%e5%9b%be class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><center><img src="/images/Image Classification/ConvNeXt .assets/ConvNeXt_Roadmap.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">深色为 ResNet-50/Swin-T；灰色为ResNet-200/Swin-B；阴影为未修改</div></center><h3 id=detailed-architectures class=heading-element><span>Detailed Architectures</span>
<a href=#detailed-architectures class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><center><img src="/images/Image Classification/ConvNeXt .assets/ConvNeXt.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">ConvNeXt</div></center><table border=0><tr><td align=center><img src="/images/Image Classification/ConvNeXt .assets/ConvNeXt_ResNet50.png"></td><td align=center><img src="/images/Image Classification/ConvNeXt .assets/ConvNeXt_ResNet200.png"></td></tr><tr><td align=center style="color:orange;border-bottom:1px solid #d9d9d9;color:#999;padding:2px">Detailed results for modernizing a ResNet-50</td><td align=center style="color:orange;border-bottom:1px solid #d9d9d9;color:#999;padding:2px">Detailed results for modernizing a ResNet-200</td></tr></table><h3 id=macro-design-宏观设计 class=heading-element><span>macro design 宏观设计</span>
<a href=#macro-design-%e5%ae%8f%e8%a7%82%e8%ae%be%e8%ae%a1 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><ul><li><p><strong>Changing stage compute ratio (78.8%&mdash;>79.4%)</strong></p><blockquote><p>每个stage的block数量：<font color=#f12c60><strong>(3，4，6，3)->(3，3，9，3)</strong></font> 和为Swin-T的stage(1，1，3，1)一致。</p></blockquote></li><li><p><strong>Changing stem to “Patchify” (79.4%&mdash;>79.5%)</strong></p><blockquote><p>输入224；经历stem，导致$4\times$下采样成56；卷积计算： $ (W-F+2P)/s+1$</p><p>传统：stride=2的$7\times7$卷积(padding为3)&mdash;>stride=2的$3\times3$max pooling（padding为1） $(224-7+2\cdot3)/2+1=112&ndash;>(112-3+2)/2=56$（pytorch向下取整）</p><p>Swin-T：stride=4的$4\times4$卷积 $(224-4)/4+1=56$</p><p>ConvNeXt ：<font color=#f12c60><strong>stride=4的$4\times4$卷积</strong></font></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 标准ResNet</span>
</span></span><span class=line><span class=cl><span class=n>stem</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_chans</span><span class=p>,</span> <span class=n>dims</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>7</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span><span class=n>padding</span><span class=o>=</span><span class=mi>3</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>nn</span><span class=o>.</span><span class=n>MaxPool2d</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># ConvNeXt</span>
</span></span><span class=line><span class=cl><span class=n>stem</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_chans</span><span class=p>,</span> <span class=n>dims</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>4</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>LayerNorm</span><span class=p>(</span><span class=n>dims</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>eps</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>,</span> <span class=n>data_format</span><span class=o>=</span><span class=s2>&#34;channels_first&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></td></tr></table></div></div></blockquote></li></ul><h3 id=resnext-794---805 class=heading-element><span>ResNeXt (79.4%&mdash;>80.5%)</span>
<a href=#resnext-794---805 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>Use more groups, expand width 使用更多的组，扩大宽度</p><blockquote><p>bottleneck的$3\times3$卷积&mdash;><font color=#f12c60><strong>depthwise conv</strong></font>(组数等于通道数)</p><p>将网络宽度增加到与Swin-T的通道数量相同（从64到<font color=#f12c60><strong>96</strong></font>）</p></blockquote><h3 id=inverted-bottleneck--805---806 class=heading-element><span>Inverted bottleneck (80.5%&mdash;>80.6%)</span>
<a href=#inverted-bottleneck--805---806 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><center><img src="/images/Image Classification/ConvNeXt .assets/ConvNeXt_Inverted_bottleneck.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Block modifications and resulted specifications</div></center><blockquote><p>(a) ResNeXt block； (b) inverted bottleneck block ； (c) b的深度卷积位置上移</p><p>d=4（维度系数）</p></blockquote><h3 id=large-kernel-size class=heading-element><span>large kernel size</span>
<a href=#large-kernel-size class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><blockquote><ul><li>使用[c图](###Inverted bottleneck (80.5%&mdash;>80.6%))深度卷积位置<font color=#f12c60><strong>上移后的倒残差结构</strong></font> <strong>(退化到79.9%)</strong></li><li>使用<font color=#f12c60><strong>$7\times7$</strong></font>卷积 <strong>（79.9% (3×3) &mdash;> 80.6%） (7×7)</strong></li></ul></blockquote><h3 id=various-layer-wise-micro-designs各种层级的微观设计 class=heading-element><span>various layer-wise micro designs各种层级的微观设计</span>
<a href=#various-layer-wise-micro-designs%e5%90%84%e7%a7%8d%e5%b1%82%e7%ba%a7%e7%9a%84%e5%be%ae%e8%a7%82%e8%ae%be%e8%ae%a1 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><center><img src="/images/Image Classification/ConvNeXt .assets/ConvNeXt_Block.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">ConvNeXt_Block</div></center><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Block</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=sa>r</span><span class=s2>&#34;&#34;&#34; ConvNeXt Block. There are two equivalent implementations:
</span></span></span><span class=line><span class=cl><span class=s2>    (1) DwConv -&gt; LayerNorm (channels_first) -&gt; 1x1 Conv -&gt; GELU -&gt; 1x1 Conv; all in (N, C, H, W)
</span></span></span><span class=line><span class=cl><span class=s2>    (2) DwConv -&gt; Permute to (N, H, W, C); LayerNorm (channels_last) -&gt; Linear -&gt; GELU -&gt; Linear; Permute back
</span></span></span><span class=line><span class=cl><span class=s2>    We use (2) as we find it slightly faster in PyTorch
</span></span></span><span class=line><span class=cl><span class=s2>    
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        dim (int): Number of input channels.
</span></span></span><span class=line><span class=cl><span class=s2>        drop_path (float): Stochastic depth rate. Default: 0.0
</span></span></span><span class=line><span class=cl><span class=s2>        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>dim</span><span class=p>,</span> <span class=n>drop_path</span><span class=o>=</span><span class=mf>0.</span><span class=p>,</span> <span class=n>layer_scale_init_value</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dwconv</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>dim</span><span class=p>,</span> <span class=n>dim</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>7</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>groups</span><span class=o>=</span><span class=n>dim</span><span class=p>)</span> <span class=c1># depthwise conv</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>norm</span> <span class=o>=</span> <span class=n>LayerNorm</span><span class=p>(</span><span class=n>dim</span><span class=p>,</span> <span class=n>eps</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>pwconv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>dim</span><span class=p>,</span> <span class=mi>4</span> <span class=o>*</span> <span class=n>dim</span><span class=p>)</span> <span class=c1># pointwise/1x1 convs, implemented with linear layers</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>act</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>GELU</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>pwconv2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>4</span> <span class=o>*</span> <span class=n>dim</span><span class=p>,</span> <span class=n>dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># gamma的作用是用于做layer scale训练策略</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>layer_scale_init_value</span> <span class=o>*</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>((</span><span class=n>dim</span><span class=p>)),</span> 
</span></span><span class=line><span class=cl>                                    <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span> <span class=k>if</span> <span class=n>layer_scale_init_value</span> <span class=o>&gt;</span> <span class=mi>0</span> <span class=k>else</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=c1># drop_path是用于stoch. depth训练策略</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>drop_path</span> <span class=o>=</span> <span class=n>DropPath</span><span class=p>(</span><span class=n>drop_path</span><span class=p>)</span> <span class=k>if</span> <span class=n>drop_path</span> <span class=o>&gt;</span> <span class=mf>0.</span> <span class=k>else</span> <span class=n>nn</span><span class=o>.</span><span class=n>Identity</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>input</span> <span class=o>=</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dwconv</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 由于用FC来做1x1conv，所以需要调换通道顺序</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span> <span class=c1># (N, C, H, W) -&gt; (N, H, W, C)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pwconv1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>act</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pwconv2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>gamma</span> <span class=o>*</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span> <span class=c1># (N, H, W, C) -&gt; (N, C, H, W)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=nb>input</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>drop_path</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span></span></span></code></pre></td></tr></table></div></div><ul><li><p>用<font color=#f12c60><strong>GELU</strong></font>代替RELU <strong>(80.6%不变)</strong></p><blockquote><p>和Swin-T一样只用<font color=#f12c60><strong>一个GELU</strong></font> <strong>(80.6%&mdash;>81.3%)</strong></p></blockquote></li><li><p>只留下<font color=#f12c60><strong>一个BN层</strong></font>（比Swin-T还少：在Block开始添加一个额外的BN层并不能提高性能）<strong>(81.3%&mdash;>81.4%)</strong></p><blockquote><p>用<font color=#f12c60><strong>LN</strong></font>代替BN <strong>(81.4%&mdash;>81.5%)</strong></p><blockquote><p>直接在ResNet基础上替换成LN，效果并不好。</p></blockquote></blockquote></li><li><p>单独的下采样层 <strong>(81.5%&mdash;>82%)</strong></p><blockquote><p>ResNet：stride=2的$3\times3$卷积，有残差结构的block则在短路连接中使用stride=2的$1\times1$卷积</p><p>Swin-T：单独采样层</p><p>ConvNeXt ：<font color=#f12c60><strong>stride=2的$2\times2$卷积</strong></font></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>#https://github.com/facebookresearch/ConvNeXt/blob/e4e7eb2fbd22d58feae617a8c989408824aa9eda/models/convnext.py#L72</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>downsample_layers</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>()</span> <span class=c1># stem and 3 intermediate downsampling conv layers</span>
</span></span><span class=line><span class=cl><span class=n>stem</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_chans</span><span class=p>,</span> <span class=n>dims</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>4</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>LayerNorm</span><span class=p>(</span><span class=n>dims</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>eps</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>,</span> <span class=n>data_format</span><span class=o>=</span><span class=s2>&#34;channels_first&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>       <span class=p>)</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>downsample_layers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>stem</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>downsample_layer</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>LayerNorm</span><span class=p>(</span><span class=n>dims</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>eps</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>,</span> <span class=n>data_format</span><span class=o>=</span><span class=s2>&#34;channels_first&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>dims</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>dims</span><span class=p>[</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>],</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>2</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>downsample_layers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>downsample_layer</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div></blockquote></li></ul><h2 id=empirical-evaluations-on-imagenet class=heading-element><span>Empirical Evaluations on ImageNet</span>
<a href=#empirical-evaluations-on-imagenet class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><h3 id=convnext-变体配置 class=heading-element><span>ConvNeXt 变体配置</span>
<a href=#convnext-%e5%8f%98%e4%bd%93%e9%85%8d%e7%bd%ae class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><blockquote><table><thead><tr><th style=text-align:center>ConvNeXt 系列</th><th style=text-align:center>C_channels</th><th style=text-align:center>B_stage_blocks</th><th style=text-align:center>IN-1K top-1 acc_input_224</th></tr></thead><tbody><tr><td style=text-align:center>ConvNeXt-T</td><td style=text-align:center>(96,192,384,768)</td><td style=text-align:center>(3,3,9,3)</td><td style=text-align:center>82.1</td></tr><tr><td style=text-align:center>ConvNeXt-S</td><td style=text-align:center>(96,192,384,768)</td><td style=text-align:center>(3,3,27,3)</td><td style=text-align:center>83.1</td></tr><tr><td style=text-align:center>ConvNeXt-B</td><td style=text-align:center>(128,256,512,1024)</td><td style=text-align:center>(3,3,27,3)</td><td style=text-align:center>83.8</td></tr><tr><td style=text-align:center>ConvNeXt-L</td><td style=text-align:center>(192,384,768,1536)</td><td style=text-align:center>(3,3,27,3)</td><td style=text-align:center>84.3</td></tr><tr><td style=text-align:center>ConvNeXt-XL</td><td style=text-align:center>(256,512,1024,2048)</td><td style=text-align:center>(3,3,27,3)</td><td style=text-align:center>IN-22K pre-trained-87.0</td></tr></tbody></table></blockquote><h3 id=training-techniques class=heading-element><span>Training Techniques</span>
<a href=#training-techniques class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h3><p>ImageNet-1K</p><table><thead><tr><th style=text-align:center>(Pre)-training config</th><th style=text-align:center>ResNet50(standard)</th><th style=text-align:center><a href=https://arxiv.org/abs/2110.00476 target=_blank rel="external nofollow noopener noreferrer">ResNet50(timm)</a></th><th style=text-align:center>ResNet50(torchvision)</th><th style=text-align:center>ConvNeXt-T</th></tr></thead><tbody><tr><td style=text-align:center>optimizer</td><td style=text-align:center>SGD</td><td style=text-align:center>LAMB</td><td style=text-align:center>SGD</td><td style=text-align:center><a href=https://arxiv.org/abs/1711.05101 target=_blank rel="external nofollow noopener noreferrer">AdamW</a></td></tr><tr><td style=text-align:center>base learning rate</td><td style=text-align:center>0.1</td><td style=text-align:center>5e-3</td><td style=text-align:center>0.5</td><td style=text-align:center>4e-3</td></tr><tr><td style=text-align:center>weight decay</td><td style=text-align:center>1e-4</td><td style=text-align:center>0.01</td><td style=text-align:center>2e-5</td><td style=text-align:center>0.05</td></tr><tr><td style=text-align:center>optimizer momentum</td><td style=text-align:center>0.9</td><td style=text-align:center>-</td><td style=text-align:center>0.9</td><td style=text-align:center>$\beta_1,\beta_2=0.9,0.999$</td></tr><tr><td style=text-align:center>batch size</td><td style=text-align:center>$8\times32=256$</td><td style=text-align:center>$4\times512=2048$</td><td style=text-align:center>$8\times128=1024$</td><td style=text-align:center>$4\times8\times128=4096$</td></tr><tr><td style=text-align:center>training epochs</td><td style=text-align:center>90</td><td style=text-align:center>600</td><td style=text-align:center>600</td><td style=text-align:center>300</td></tr><tr><td style=text-align:center>learning rate schedule</td><td style=text-align:center>StepLR<br>(step=30,gamma=0.1)</td><td style=text-align:center>cosine decay</td><td style=text-align:center>cosine decay</td><td style=text-align:center>cosine decay</td></tr><tr><td style=text-align:center>warmup epochs</td><td style=text-align:center>-</td><td style=text-align:center>5</td><td style=text-align:center>5</td><td style=text-align:center>20</td></tr><tr><td style=text-align:center>warmup schedule</td><td style=text-align:center>-</td><td style=text-align:center>linear</td><td style=text-align:center>linear</td><td style=text-align:center>linear</td></tr></tbody></table><blockquote><p>The effective batch size = <code>--nodes</code> * <code>--ngpus</code> * <code>--batch_size</code> * <code>--update_freq</code>. In the example above, the effective batch size is <code>4*8*128*1 = 4096</code></p></blockquote><p><strong>数据增强</strong></p><table><thead><tr><th style=text-align:center>(Pre)-training config</th><th style=text-align:center>ResNet50(standard)</th><th style=text-align:center><a href=https://arxiv.org/abs/2110.00476 target=_blank rel="external nofollow noopener noreferrer">ResNet50(timm)</a></th><th style=text-align:center><a href=https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/ target=_blank rel="external nofollow noopener noreferrer">ResNet50(torchvision)</a></th><th style=text-align:center>ConvNeXt-T</th></tr></thead><tbody><tr><td style=text-align:center><a href=https://arxiv.org/abs/1710.09412 target=_blank rel="external nofollow noopener noreferrer">Mixup</a></td><td style=text-align:center>-</td><td style=text-align:center>0.2</td><td style=text-align:center>0.2</td><td style=text-align:center>0.8</td></tr><tr><td style=text-align:center><a href="https://arxiv.org/abs/1905.04899?context=cs.CV" target=_blank rel="external nofollow noopener noreferrer">Cutmix</a></td><td style=text-align:center>-</td><td style=text-align:center>1.0</td><td style=text-align:center>1.0</td><td style=text-align:center>1.0</td></tr><tr><td style=text-align:center><a href=https://arxiv.org/abs/1909.13719 target=_blank rel="external nofollow noopener noreferrer">RandAugment</a></td><td style=text-align:center>-</td><td style=text-align:center>(7,0.5)</td><td style=text-align:center>auto_augment=&lsquo;ta_wide&rsquo;</td><td style=text-align:center>(9,0.5)</td></tr></tbody></table><p><strong>正则化</strong></p><table><thead><tr><th style=text-align:center>(Pre)-training config</th><th style=text-align:center>ResNet50(standard)</th><th style=text-align:center><a href=https://arxiv.org/abs/2110.00476 target=_blank rel="external nofollow noopener noreferrer">ResNet50(timm)</a></th><th style=text-align:center><a href=https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/ target=_blank rel="external nofollow noopener noreferrer">ResNet50(torchvision)</a></th><th style=text-align:center>ConvNeXt-T</th></tr></thead><tbody><tr><td style=text-align:center><a href=https://arxiv.org/abs/1603.09382 target=_blank rel="external nofollow noopener noreferrer">Stochastic Depth</a></td><td style=text-align:center>-</td><td style=text-align:center>0.05</td><td style=text-align:center>-</td><td style=text-align:center>0.1</td></tr><tr><td style=text-align:center><a href=https://arxiv.org/abs/1512.00567 target=_blank rel="external nofollow noopener noreferrer">Label Smoothing</a></td><td style=text-align:center>-</td><td style=text-align:center>0.1</td><td style=text-align:center>0.1</td><td style=text-align:center>0.1</td></tr><tr><td style=text-align:center><a href=https://arxiv.org/abs/2103.17239 target=_blank rel="external nofollow noopener noreferrer">Layer Scale</a></td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>1e-6</td></tr><tr><td style=text-align:center><a href="https://epubs.siam.org/doi/abs/10.1137/0330046?journalCode=sjcodc" target=_blank rel="external nofollow noopener noreferrer">EMA</a></td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>0.99998</td><td style=text-align:center>0.9999</td></tr></tbody></table><p><strong>Top-1 acc</strong></p><table><thead><tr><th style=text-align:center>(Pre)-training config</th><th style=text-align:center>ResNet50(standard)</th><th style=text-align:center><a href=https://arxiv.org/abs/2110.00476 target=_blank rel="external nofollow noopener noreferrer">ResNet50(timm)</a></th><th style=text-align:center><a href=https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/ target=_blank rel="external nofollow noopener noreferrer">ResNet50(torchvision)</a></th><th style=text-align:center>ConvNeXt-T</th></tr></thead><tbody><tr><td style=text-align:center>Top-1 acc</td><td style=text-align:center>75.3</td><td style=text-align:center>80.4</td><td style=text-align:center>80.674</td><td style=text-align:center>82.1</td></tr></tbody></table><h2 id=拓展阅读 class=heading-element><span>拓展阅读</span>
<a href=#%e6%8b%93%e5%b1%95%e9%98%85%e8%af%bb class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p><a href=https://zhuanlan.zhihu.com/p/456432890? target=_blank rel="external nofollow noopener noreferrer">ConvNeXt：手把手教你改模型</a></p><p><a href=https://arxiv.org/abs/2110.00476 target=_blank rel="external nofollow noopener noreferrer">ResNet strikes back: An improved training procedure in timm</a></p><p><a href=https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/ target=_blank rel="external nofollow noopener noreferrer">How to Train State-Of-The-Art Models Using TorchVision’s Latest Primitives</a></p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2023-06-02 18:22:27">更新于 2023-06-02&nbsp;</span></div><div class=post-info-license><span><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 X" data-sharer=twitter data-url=http://fengchen321.github.io/posts/deeplearning/image-classification/convnext-/ data-title=ConvNeXt data-hashtags="Deep Learning,图像分类模型"><i class="fa-brands fa-x-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=http://fengchen321.github.io/posts/deeplearning/image-classification/convnext-/ data-hashtag="Deep Learning"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=http://fengchen321.github.io/posts/deeplearning/image-classification/convnext-/ data-title=ConvNeXt><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/deep-learning/ class=post-tag title="标签 - Deep Learning">Deep Learning</a><a href=/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/ class=post-tag title="标签 - 图像分类模型">图像分类模型</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/deeplearning/image-classification/efficientnet/ class=post-nav-item rel=prev title=EfficientNet><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>EfficientNet</a><a href=/posts/deeplearning/image-classification/automl/ class=post-nav-item rel=next title=AutoML>AutoML<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article><aside class=toc id=toc-auto aria-label=目录><h2 class=toc-title>目录&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class="toc-content always-active" id=toc-content-auto></div></aside></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.139.0"><img class=hugo-icon src=/images/hugo.min.svg alt="Hugo logo"> Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.3.15"><img class=fixit-icon src=/images/fixit.min.svg alt="FixIt logo"> FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2024 - 2025</span><span class=author itemprop=copyrightHolder>
<a href=/>fengchen</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class="variant-numeric d-none">0%</span></div></div><div id=mask></div><div class=reading-progress-bar style=left:0;top:0></div><noscript><div class=noscript-warning>该网站在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=preload href=/lib/katex/katex.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/katex/katex.min.css></noscript><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><script src=/lib/autocomplete/autocomplete.min.js defer></script><script src=/lib/sharer/sharer.min.js async defer></script><script src=/lib/katex/katex.min.js defer></script><script src=/lib/katex/auto-render.min.js defer></script><script src=/lib/katex/copy-tex.min.js defer></script><script src=/lib/katex/mhchem.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.js defer></script><script>window.config={code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:100},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50},version:"v0.3.15"}</script><script src=/js/theme.min.js defer></script></body></html>