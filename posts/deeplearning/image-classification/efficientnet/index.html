<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>EfficientNet - fengchen</title><meta name=author content><meta name=description content="EfficientNet"><meta name=keywords content='Deep Learning,图像分类模型'><meta itemprop=name content="EfficientNet"><meta itemprop=description content="EfficientNet"><meta itemprop=datePublished content="2023-06-02T18:22:27+08:00"><meta itemprop=dateModified content="2023-06-02T18:22:27+08:00"><meta itemprop=wordCount content="3243"><meta itemprop=keywords content="Deep Learning,图像分类模型"><meta property="og:url" content="http://fengchen321.github.io/posts/deeplearning/image-classification/efficientnet/"><meta property="og:site_name" content="fengchen"><meta property="og:title" content="EfficientNet"><meta property="og:description" content="EfficientNet"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-06-02T18:22:27+08:00"><meta property="article:modified_time" content="2023-06-02T18:22:27+08:00"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="图像分类模型"><meta name=twitter:card content="summary"><meta name=twitter:title content="EfficientNet"><meta name=twitter:description content="EfficientNet"><meta name=application-name content="FixIt"><meta name=apple-mobile-web-app-title content="FixIt"><meta name=theme-color data-light=#f8f8f8 data-dark=#252627 content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=canonical type=text/html href=http://fengchen321.github.io/posts/deeplearning/image-classification/efficientnet/ title="EfficientNet - fengchen"><link rel=prev type=text/html href=http://fengchen321.github.io/posts/deeplearning/image-classification/inception/ title=Inception><link rel=next type=text/html href=http://fengchen321.github.io/posts/deeplearning/image-classification/convnext-/ title=ConvNeXt><link rel=stylesheet href=/css/style.min.css><link rel=preload href=/lib/fontawesome-free/all.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload href=/lib/animate/animate.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"EfficientNet","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"http:\/\/fengchen321.github.io\/posts\/deeplearning\/image-classification\/efficientnet\/"},"genre":"posts","keywords":"Deep Learning, 图像分类模型","wordcount":3243,"url":"http:\/\/fengchen321.github.io\/posts\/deeplearning\/image-classification\/efficientnet\/","datePublished":"2023-06-02T18:22:27+08:00","dateModified":"2023-06-02T18:22:27+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"作者"},"description":"EfficientNet"}</script><script src=/js/head/color-scheme.min.js></script></head><body data-header-desktop=sticky data-header-mobile=auto><div class=wrapper data-page-style=normal><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=fengchen><span class=header-title-text>fengchen</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/about/ title=关于本站>关于本站</a></li><li class=menu-item><a class=menu-link href=/posts/>所有文章</a></li><li class=menu-item><a class=menu-link href=/tags/>标签</a></li><li class=menu-item><a class=menu-link href=/categories/>分类</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=fengchen><span class=header-title-text>fengchen</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/about/ title=关于本站>关于本站</a></li><li class=menu-item><a class=menu-link href=/posts/>所有文章</a></li><li class=menu-item><a class=menu-link href=/tags/>标签</a></li><li class=menu-item><a class=menu-link href=/categories/>分类</a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=container><aside class="aside-collection animate__animated animate__fadeIn animate__faster" aria-label=合集></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>EfficientNet</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><span class=author><i class="fa-solid fa-user-circle" aria-hidden=true></i>
Anonymous</span></span><span class=post-included-in>&nbsp;收录于 <a href=/categories/deep-learning/ class=post-category title="分类 - Deep Learning"><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> Deep Learning</a></span></div><div class=post-meta-line><span title="发布于 2023-06-02 18:22:27"><i class="fa-solid fa-calendar-days fa-fw me-1" aria-hidden=true></i><time datetime=2023-06-02>2023-06-02</time></span>&nbsp;<span title="3243 字"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 3300 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 7 分钟</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#scaling-dimensions>Scaling Dimensions</a></li><li><a href=#problem-formulation>Problem Formulation</a></li><li><a href=#efficientnet-architecture>EfficientNet Architecture</a></li><li><a href=#拓展阅读>拓展阅读</a></li></ul><ul><li><a href=#fused-mbconv>Fused-MBConv</a></li><li><a href=#efficientnetv2-architecture>EfficientNetV2 Architecture</a></li><li><a href=#progressive-learning渐进式学习>progressive learning渐进式学习</a></li><li><a href=#拓展阅读-1>拓展阅读</a></li></ul></nav></div></div><div class=content id=content><h2 id=efficientnet class=heading-element><span>EfficientNet</span>
<a href=#efficientnet class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/1905.11946 target=_blank rel="external nofollow noopener noreferrer">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a>
作者：Mingxing Tan, Quoc V. Le
发表时间：(ICML 2019)</p><p><a href=https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet target=_blank rel="external nofollow noopener noreferrer">Official Code</a></p><p><a href=https://github.com/lukemelas/EfficientNet-PyTorch target=_blank rel="external nofollow noopener noreferrer">EfficientNet PyTorch</a></p></blockquote><p>EfficientNet 是一组针对<strong>FLOPs和参数效率</strong>进行优化的模型。它利用NAS搜索<strong>基线EfficientNet-B0</strong>，它在准确性和FLOPs方面有更好的权衡。然后使用复合缩放策略对基线模型进行缩放，以获得一系列模型B1-B7。</p><center><img src="/images/Image Classification/EfficientNet.assets/EfficientNetV1_Model_scaling.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Model_Scaling</div></center><center><img src="/images/Image Classification/EfficientNet.assets/EfficientNetV1_B0_different_methods.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Scaling Up EfficientNet-B0 with Different Methods</div></center><blockquote><p>增加网络的深度<strong>depth</strong>能够得到更加丰富、复杂的特征并且能够很好的应用到其它任务中。但网络的深度过深会面临梯度消失，训练困难的问题。<strong>(ResNet)</strong></p><p>增加网络的<strong>width</strong>能够获得更高细粒度的特征并且也更容易训练，但对于width很大而深度较浅的网络往往很难学习到更深层次的特征。<strong>(Inception)</strong></p><p>增加输入网络的<strong>图像分辨率</strong>能够潜在得获得更高细粒度的特征模板，但对于非常高的输入分辨率，准确率的增益也会减小，并且大分辨率图像会增加计算量。</p></blockquote><h2 id=scaling-dimensions class=heading-element><span>Scaling Dimensions</span>
<a href=#scaling-dimensions class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><center><img src="/images/Image Classification/EfficientNet.assets/EfficientNetV1_Sacling_up_Model.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Scaling Up a Baseline Model with Different Network Width (w), Depth (d), and Resolution (r) Coefficient</div></center><blockquote><p>扩大网络中深度、宽度或者分辨率的任一维度能提高模型的准确率，但随着模型的扩大，这种准确率的增益效果会逐步消失；</p><p>Scaling up any dimension of network width, depth, or resolution improves accuracy, but the accuracy gain diminishes for bigger models.</p></blockquote><center><img src="/images/Image Classification/EfficientNet.assets/EfficientNetV1_Scaling_width.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Scaling Network Width for Different Baseline Networks</div></center><blockquote><p>$(d=1.0,r=1.0)$：18个卷积层，分辨率为$224\times224$</p><p>$(d=2.0,r=1.3)$：36个卷积层，分辨率为$299\times299$</p><p>为了更好的准确率和效率，很有必要去平衡提升网络中深度、宽度和分辨率的所有维度。</p><p>In order to pursue better accuracy and efficiency, it is critical to balance all dimensions of network width, depth, and resolution during ConvNet scaling.</p></blockquote><h2 id=problem-formulation class=heading-element><span>Problem Formulation</span>
<a href=#problem-formulation class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2>$$
N = \bigodot_{i=1...s} F_i^{L_i}(X_{<h _i,w_i,c_i>})
$$<blockquote><p>$ \bigodot_{i=1&mldr;s}$：连乘运算</p><p>$F_i$表示一个运算操作；$F_i^{L_i}$表示在第i个stage中$F_i$运算被重复执行了$L_i$次</p><p>$X$表示第i个stage的特征矩阵（输入张量）</p><p>$&lt;H_i,W_i,C_i>$表示$X$的高宽和通道数</p></blockquote>$$
max_{d,w,r} \ \ Accuracy(N(d,w,r))\\
s.t. \ N(d,w,r)=\bigodot_{i=1...s} \hat F_i^{\hat L_i}(X_{<r \dot {\hat h_i},r\dot {\hat w_i},w\dot {\hat c_i}>})\\
Memory(N)\leq target\_memory\\
FLOPS(N)\leq target\_flops
$$<blockquote><p>$d$用来缩放深度$\hat {L_i}$</p><p>$r$用来缩放分辨率即影响$\hat{H_i},\hat{W_i}$</p><p>$w$用来缩放特征矩阵的通道数$\hat{C_i}$</p></blockquote>$$
depth:d=\alpha^\phi\\
width:w=\beta^\phi\\
resolution:r=\gamma^\phi\\
s.t. \ \alpha \cdot \beta^2\cdot\gamma^2 \approx2\\
\alpha\geq1,\beta\geq1,\gamma\geq1
$$<blockquote><p>FLOPs（理论计算量）与<strong>depth</strong>的关系：当depth翻倍，FLOPs也==翻倍==。</p><p>FLOPs与<strong>width</strong>的关系：当width翻倍（即channal翻倍），FLOPs会==翻4倍==</p><blockquote><p>当width翻倍，输入特征矩阵的channels和输出特征矩阵的channels或卷积核的个数都会翻倍，所以FLOPs会翻4倍</p></blockquote><p>FLOPs与<strong>resolution</strong>的关系：当resolution翻倍，FLOPs会==翻4倍==</p><p>总的FLOPs倍率可以用近似用$(\alpha \cdot \beta^{2} \cdot \gamma^{2})^{\phi}$表示</p><blockquote><p>：$\beta^2：c_i,c_o;\gamma^2:h,w$</p></blockquote></blockquote><ol><li>固定$\phi=1$，基于上述约束条件进行搜索，EfficientNet_B0的最佳参数为$\alpha=1.2,\beta=1.1.\gamma=1.15$。</li><li>固定$\alpha=1.2,\beta=1.1.\gamma=1.15$，在EfficientNetB-0的基础上使用不同的$ \phi$分别得到EfficientNetB1-B7。</li></ol><h2 id=efficientnet-architecture class=heading-element><span>EfficientNet Architecture</span>
<a href=#efficientnet-architecture class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><center><img src="/images/Image Classification/EfficientNet.assets/EfficientNetV1_B0.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">EfficientNet-B0 baseline network</div></center>> 其中卷积层后默认都有**BN**以及**Swish**激活函数<center><img src="/images/Image Classification/EfficientNet.assets/EfficientNetV1_MBConv.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">MBConv</div></center><blockquote><ul><li>第一个升维的$1\times1$卷积层，它的卷积核个数是输入特征矩阵channel的n倍(这里的n对应Operator里的MBConv<strong>n</strong>)</li><li>当n=1时，不要第一个升维的$1\times1$卷积层，即Stage2中的MBConv结构都没有第一个升维的1x1卷积层（这和MobileNetV3网络类似）</li><li>关于shortcut连接，仅当输入MBConv结构的特征矩阵与输出的特征矩阵shape相同时才存在</li></ul><p>注意：在源码中只有使用到shortcut的MBConv模块才有Dropout层；<strong>Dropout层的<code>drop_rate</code>是从0递增到0.2的</strong>，是<a href=https://arxiv.org/abs/1603.09382 target=_blank rel="external nofollow noopener noreferrer">Stochastic Depth</a>，即会随机丢掉整个block的主分支（只剩捷径分支，相当于直接跳过了这个block）也可以理解为减少了网络的深度。</p><blockquote></blockquote></blockquote><center><img src="/images/Image Classification/EfficientNet.assets/EfficientNetV1_MBConv_SE.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">SE</div></center><blockquote><p>由一个全局平均池化，两个全连接层组成。</p><ul><li><p>第一个全连接层的节点个数是<strong>输入该MBConv模块的特征矩阵channels的1/4</strong>(MobileNetV3是feature map的channels的1/4)，且使用Swish激活函数。</p></li><li><p>第二个全连接层的节点个数等于Depthwise Conv层输出的特征矩阵channels，且使用Sigmoid激活函数。</p></li></ul></blockquote><table><thead><tr><th style=text-align:center>model</th><th style=text-align:center>width_coefficient</th><th style=text-align:center>depth_coefficient</th><th style=text-align:center>resolution</th><th style=text-align:center>dropout_rate</th></tr></thead><tbody><tr><td style=text-align:center>efficientnet-b0</td><td style=text-align:center>1.0</td><td style=text-align:center>1.0</td><td style=text-align:center>224</td><td style=text-align:center>0.2</td></tr><tr><td style=text-align:center>efficientnet-b1</td><td style=text-align:center>1.0</td><td style=text-align:center>1.1</td><td style=text-align:center>240</td><td style=text-align:center>0.2</td></tr><tr><td style=text-align:center>efficientnet-b2</td><td style=text-align:center>1.1</td><td style=text-align:center>1.2</td><td style=text-align:center>260</td><td style=text-align:center>0.3</td></tr><tr><td style=text-align:center>efficientnet-b3</td><td style=text-align:center>1.2</td><td style=text-align:center>1.4</td><td style=text-align:center>300</td><td style=text-align:center>0.3</td></tr><tr><td style=text-align:center>efficientnet-b4</td><td style=text-align:center>1.4</td><td style=text-align:center>1.8</td><td style=text-align:center>380</td><td style=text-align:center>0.4</td></tr><tr><td style=text-align:center>efficientnet-b5</td><td style=text-align:center>1.6</td><td style=text-align:center>2.2</td><td style=text-align:center>456</td><td style=text-align:center>0.4</td></tr><tr><td style=text-align:center>efficientnet-b6</td><td style=text-align:center>1.8</td><td style=text-align:center>2.6</td><td style=text-align:center>528</td><td style=text-align:center>0.5</td></tr><tr><td style=text-align:center>efficientnet-b7</td><td style=text-align:center>2.0</td><td style=text-align:center>3.1</td><td style=text-align:center>600</td><td style=text-align:center>0.5</td></tr><tr><td style=text-align:center>efficientnet-b8</td><td style=text-align:center>2.2</td><td style=text-align:center>3.6</td><td style=text-align:center>672</td><td style=text-align:center>0.5</td></tr><tr><td style=text-align:center>efficientnet-12</td><td style=text-align:center>4.3</td><td style=text-align:center>5.3</td><td style=text-align:center>800</td><td style=text-align:center>0.5</td></tr></tbody></table><blockquote><ul><li><p><strong>width_coefficient</strong>代表channel维度上的倍率因子</p><blockquote><p>比如在 EfficientNetB0中Stage1的$3\times3$卷积层所使用的卷积核个数是32，那么在B6中就是$32 \times 1.8=57.6$,接着取整到离它最近的8的整数倍即56，其它Stage同理。</p></blockquote></li><li><p><strong>depth_coefficient</strong>代表depth维度上的倍率因子（仅针对<code>Stage2</code>到<code>Stage8</code>）</p><blockquote><p>比如在EfficientNetB0中Stage7的$ {\widehat L}_i=4 $那么在B6中就是$4 \times 2.6=10.4$，接着向上取整即11。</p></blockquote></li></ul><ul><li><strong>dropout_rate</strong>是最后一个全连接层前的<code>dropout</code>层（在<code>stage9</code>的Pooling与FC之间）的<code>dropout_rate</code>。</li></ul></blockquote><h2 id=拓展阅读 class=heading-element><span>拓展阅读</span>
<a href=#%e6%8b%93%e5%b1%95%e9%98%85%e8%af%bb class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p><a href=https://blog.csdn.net/qq_37541097/article/details/114434046 target=_blank rel="external nofollow noopener noreferrer">EfficientNet网络详解</a></p><h2 id=efficientnetv2 class=heading-element><span>EfficientNetV2</span>
<a href=#efficientnetv2 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><blockquote><p>文章标题：<a href=https://arxiv.org/abs/2104.00298 target=_blank rel="external nofollow noopener noreferrer">EfficientNetV2: Smaller Models and Faster Training</a>
作者：Mingxing Tan, Quoc V. Le
发表时间：(ICML 2021)</p><p><a href=https://github.com/google/automl/tree/master/efficientnetv2 target=_blank rel="external nofollow noopener noreferrer">Official Code</a></p><p><a href=https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/efficientnet.py target=_blank rel="external nofollow noopener noreferrer">PyTorch Image Models</a></p></blockquote><p><strong>EfficientNetV1的训练瓶颈</strong></p><blockquote><p><strong>大图像尺寸导致了大量的内存使用，训练速度非常慢</strong>。</p><blockquote><p>解决方法：降低训练图像的尺寸</p></blockquote><p><strong>深度卷积在网络浅层（前期）中速度缓慢</strong>，但在后期阶段有效。（无法充分利用现有的一些加速器）</p><blockquote><p>解决方法：引入Fused-MBConv结构</p></blockquote><p><strong>同等的扩大每个stage是次优的</strong>。在EfficientNetV1中，每个stage的深度和宽度都是同等放大的。但每个stage对网络的训练速度以及参数数量的贡献并不相同</p><blockquote><p>解决方法：非均匀的缩放策略来缩放模型</p></blockquote></blockquote><h2 id=fused-mbconv class=heading-element><span>Fused-MBConv</span>
<a href=#fused-mbconv class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><center><img src="/images/Image Classification/EfficientNet.assets/EfficientNetV2_Fused_MBConv.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Structure of MBConv and Fused-MBConv.</div></center><blockquote><p>源码没有使用SE模块</p></blockquote><center><img src="/images/Image Classification/EfficientNet.assets/EfficientNetV2_Replace_MBConv.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Replacing MBConv with Fused-MBConv</div></center><blockquote><p>只替换stage1-3，用NAS搜索出来的结果</p></blockquote><h2 id=efficientnetv2-architecture class=heading-element><span>EfficientNetV2 Architecture</span>
<a href=#efficientnetv2-architecture class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><center><img src="/images/Image Classification/EfficientNet.assets/EfficientNetV2_S.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">EfficientNetV2_S</div></center><blockquote><p>与EfficientNetV1的不同点</p><ul><li>除了使用MBConv模块，还使用Fused-MBConv模块</li><li>会使用较小的expansion ratio</li><li>偏向使用更小的kernel_size($3\times3$)</li><li>移除了EfficientNetV1中最后一个步距为1的stage（V1中的stage8）</li></ul></blockquote><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>#################### EfficientNet V2 configs ####################</span>
</span></span><span class=line><span class=cl><span class=c1># r代表当前Stage中Operator重复堆叠的次数</span>
</span></span><span class=line><span class=cl><span class=c1># k代表kernel_size</span>
</span></span><span class=line><span class=cl><span class=c1># s代表步距stride</span>
</span></span><span class=line><span class=cl><span class=c1># e代表expansion ratio</span>
</span></span><span class=line><span class=cl><span class=c1># i代表input channels</span>
</span></span><span class=line><span class=cl><span class=c1># o代表output channels</span>
</span></span><span class=line><span class=cl><span class=c1># c代表conv_type，1代表Fused-MBConv，0代表MBConv（默认为MBConv）</span>
</span></span><span class=line><span class=cl><span class=c1># se代表使用SE模块，以及se_ratio</span>
</span></span><span class=line><span class=cl><span class=n>v2_base_block</span> <span class=o>=</span> <span class=p>[</span>  <span class=c1># The baseline config for v2 models.</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r1_k3_s1_e1_i32_o16_c1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r2_k3_s2_e4_i16_o32_c1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r2_k3_s2_e4_i32_o48_c1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r3_k3_s2_e4_i48_o96_se0.25&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r5_k3_s1_e6_i96_o112_se0.25&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r8_k3_s2_e6_i112_o192_se0.25&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>v2_s_block</span> <span class=o>=</span> <span class=p>[</span>  <span class=c1># about base * (width1.4, depth1.8)</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r2_k3_s1_e1_i24_o24_c1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r4_k3_s2_e4_i24_o48_c1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r4_k3_s2_e4_i48_o64_c1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r6_k3_s2_e4_i64_o128_se0.25&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r9_k3_s1_e6_i128_o160_se0.25&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r15_k3_s2_e6_i160_o256_se0.25&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>v2_m_block</span> <span class=o>=</span> <span class=p>[</span>  <span class=c1># about base * (width1.6, depth2.2)</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r3_k3_s1_e1_i24_o24_c1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r5_k3_s2_e4_i24_o48_c1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r5_k3_s2_e4_i48_o80_c1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r7_k3_s2_e4_i80_o160_se0.25&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r14_k3_s1_e6_i160_o176_se0.25&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r18_k3_s2_e6_i176_o304_se0.25&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r5_k3_s1_e6_i304_o512_se0.25&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>v2_l_block</span> <span class=o>=</span> <span class=p>[</span>  <span class=c1># about base * (width2.0, depth3.1)</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r4_k3_s1_e1_i32_o32_c1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r7_k3_s2_e4_i32_o64_c1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r7_k3_s2_e4_i64_o96_c1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r10_k3_s2_e4_i96_o192_se0.25&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r19_k3_s1_e6_i192_o224_se0.25&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r25_k3_s2_e6_i224_o384_se0.25&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;r7_k3_s1_e6_i384_o640_se0.25&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>efficientnetv2_params</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1># (block, width, depth, train_size, eval_size, dropout, randaug, mixup, aug)</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;efficientnetv2-s&#39;</span><span class=p>:</span>  <span class=c1># 83.9% @ 22M</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=n>v2_s_block</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mi>300</span><span class=p>,</span> <span class=mi>384</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=s1>&#39;randaug&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;efficientnetv2-m&#39;</span><span class=p>:</span>  <span class=c1># 85.2% @ 54M</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=n>v2_m_block</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mi>384</span><span class=p>,</span> <span class=mi>480</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>,</span> <span class=s1>&#39;randaug&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;efficientnetv2-l&#39;</span><span class=p>:</span>  <span class=c1># 85.7% @ 120M</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=n>v2_l_block</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mi>384</span><span class=p>,</span> <span class=mi>480</span><span class=p>,</span> <span class=mf>0.4</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=s1>&#39;randaug&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></td></tr></table></div></div><h2 id=progressive-learning渐进式学习 class=heading-element><span>progressive learning渐进式学习</span>
<a href=#progressive-learning%e6%b8%90%e8%bf%9b%e5%bc%8f%e5%ad%a6%e4%b9%a0 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p>在训练早期，先对图像尺寸小且正则化程度较弱的网络进行训练(如dropout、data augmentation)，然后逐渐增大图像尺寸并加入更强的正则化。</p><p>建立在渐进调整大小的基础上，但通过动态（自适应）调整正则化（Dropout, Rand Augment, Mixup）</p><center><img src="/images/Image Classification/EfficientNet.assets/EfficientNetV2_Algorithm_1.png"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">EfficientNetV2_Algorithm_1.</div></center><h2 id=拓展阅读-1 class=heading-element><span>拓展阅读</span>
<a href=#%e6%8b%93%e5%b1%95%e9%98%85%e8%af%bb-1 class=heading-mark><svg class="octicon octicon-link" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5.0 114.95 4.95l-2.5 2.5a3.5 3.5.0 01-4.95.0.751.751.0 01.018-1.042.751.751.0 011.042-.018 1.998 1.998.0 002.83.0l2.5-2.5a2.002 2.002.0 00-2.83-2.83l-1.25 1.25a.751.751.0 01-1.042-.018.751.751.0 01-.018-1.042zm-4.69 9.64a1.998 1.998.0 002.83.0l1.25-1.25a.751.751.0 011.042.018.751.751.0 01.018 1.042l-1.25 1.25a3.5 3.5.0 11-4.95-4.95l2.5-2.5a3.5 3.5.0 014.95.0.751.751.0 01-.018 1.042.751.751.0 01-1.042.018 1.998 1.998.0 00-2.83.0l-2.5 2.5a1.998 1.998.0 000 2.83z"/></svg></a></h2><p><a href=https://blog.csdn.net/qq_37541097/article/details/116933569 target=_blank rel="external nofollow noopener noreferrer">EfficientNetV2网络详解</a></p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2023-06-02 18:22:27">更新于 2023-06-02&nbsp;</span></div><div class=post-info-license><span><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 X" data-sharer=twitter data-url=http://fengchen321.github.io/posts/deeplearning/image-classification/efficientnet/ data-title=EfficientNet data-hashtags="Deep Learning,图像分类模型"><i class="fa-brands fa-x-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=http://fengchen321.github.io/posts/deeplearning/image-classification/efficientnet/ data-hashtag="Deep Learning"><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=http://fengchen321.github.io/posts/deeplearning/image-classification/efficientnet/ data-title=EfficientNet><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/deep-learning/ class=post-tag title="标签 - Deep Learning">Deep Learning</a><a href=/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/ class=post-tag title="标签 - 图像分类模型">图像分类模型</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/deeplearning/image-classification/inception/ class=post-nav-item rel=prev title=Inception><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>Inception</a><a href=/posts/deeplearning/image-classification/convnext-/ class=post-nav-item rel=next title=ConvNeXt>ConvNeXt<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article><aside class=toc id=toc-auto aria-label=目录><h2 class=toc-title>目录&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class="toc-content always-active" id=toc-content-auto></div></aside></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.139.0"><img class=hugo-icon src=/images/hugo.min.svg alt="Hugo logo"> Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.3.15"><img class=fixit-icon src=/images/fixit.min.svg alt="FixIt logo"> FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2024</span><span class=author itemprop=copyrightHolder>
<a href=/></a></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class="variant-numeric d-none">0%</span></div></div><div id=mask></div><noscript><div class=noscript-warning>该网站在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=preload href=/lib/katex/katex.min.css as=style onload='this.removeAttribute("onload"),this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/katex/katex.min.css></noscript><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><script src=/lib/autocomplete/autocomplete.min.js defer></script><script src=/lib/sharer/sharer.min.js async defer></script><script src=/lib/katex/katex.min.js defer></script><script src=/lib/katex/auto-render.min.js defer></script><script src=/lib/katex/copy-tex.min.js defer></script><script src=/lib/katex/mhchem.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.js defer></script><script>window.config={code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:100},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50},version:"v0.3.15"}</script><script src=/js/theme.min.js defer></script></body></html>