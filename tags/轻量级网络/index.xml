<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>轻量级网络 - 标签 - fengchen</title><link>https://fengchen321.github.io/tags/%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%BD%91%E7%BB%9C/</link><description>fengchen</description><generator>Hugo 0.139.0 &amp; FixIt v0.3.15</generator><language>zh-CN</language><lastBuildDate>Sat, 03 Jun 2023 18:22:27 +0800</lastBuildDate><atom:link href="https://fengchen321.github.io/tags/%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%BD%91%E7%BB%9C/index.xml" rel="self" type="application/rss+xml"/><item><title>Distilling knowledge</title><link>https://fengchen321.github.io/posts/deeplearning/light-weight/distilling_knowledge/</link><pubDate>Sat, 03 Jun 2023 18:22:27 +0800</pubDate><guid>https://fengchen321.github.io/posts/deeplearning/light-weight/distilling_knowledge/</guid><category domain="https://fengchen321.github.io/categories/deep-learning/">Deep Learning</category><description>&lt;h2 id="distilling-knowledge" class="heading-element">&lt;span>Distilling knowledge&lt;/span>
 &lt;a href="#distilling-knowledge" class="heading-mark">
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true">&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z">&lt;/path>&lt;/svg>
 &lt;/a>
&lt;/h2>&lt;blockquote>
&lt;p>文章标题：&lt;a href="https://arxiv.org/abs/1503.02531"target="_blank" rel="external nofollow noopener noreferrer">Distilling the knowledge in a neural network&lt;/a>&lt;/p></description></item><item><title>GhostNet</title><link>https://fengchen321.github.io/posts/deeplearning/light-weight/ghostnet/</link><pubDate>Sat, 03 Jun 2023 18:22:27 +0800</pubDate><guid>https://fengchen321.github.io/posts/deeplearning/light-weight/ghostnet/</guid><category domain="https://fengchen321.github.io/categories/deep-learning/">Deep Learning</category><description>&lt;h2 id="ghostnet" class="heading-element">&lt;span>GhostNet&lt;/span>
 &lt;a href="#ghostnet" class="heading-mark">
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true">&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z">&lt;/path>&lt;/svg>
 &lt;/a>
&lt;/h2>&lt;blockquote>
&lt;p>文章标题：&lt;a href="https://arxiv.org/abs/1911.11907"target="_blank" rel="external nofollow noopener noreferrer">GhostNet: More Features from Cheap Operations&lt;/a>&lt;/p></description></item><item><title>LCNet</title><link>https://fengchen321.github.io/posts/deeplearning/light-weight/lcnet/</link><pubDate>Sat, 03 Jun 2023 18:22:27 +0800</pubDate><guid>https://fengchen321.github.io/posts/deeplearning/light-weight/lcnet/</guid><category domain="https://fengchen321.github.io/categories/deep-learning/">Deep Learning</category><description>&lt;h2 id="pp-lcnet" class="heading-element">&lt;span>PP-LCNet&lt;/span>
 &lt;a href="#pp-lcnet" class="heading-mark">
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true">&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z">&lt;/path>&lt;/svg>
 &lt;/a>
&lt;/h2>&lt;blockquote>
&lt;p>文章标题：&lt;a href="https://arxiv.org/abs/2109.15099"target="_blank" rel="external nofollow noopener noreferrer">PP-LCNet: A Lightweight CPU Convolutional Neural Network&lt;/a>&lt;/p></description></item><item><title>MobileNet</title><link>https://fengchen321.github.io/posts/deeplearning/light-weight/mobilenet/</link><pubDate>Sat, 03 Jun 2023 18:22:27 +0800</pubDate><guid>https://fengchen321.github.io/posts/deeplearning/light-weight/mobilenet/</guid><category domain="https://fengchen321.github.io/categories/deep-learning/">Deep Learning</category><description>&lt;h2 id="mobilenetv1" class="heading-element">&lt;span>MobileNetV1&lt;/span>
 &lt;a href="#mobilenetv1" class="heading-mark">
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true">&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z">&lt;/path>&lt;/svg>
 &lt;/a>
&lt;/h2>&lt;blockquote>
&lt;p>文章标题：&lt;a href="https://arxiv.org/abs/1704.04861"target="_blank" rel="external nofollow noopener noreferrer">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications&lt;/a>&lt;/p></description></item><item><title>NAS</title><link>https://fengchen321.github.io/posts/deeplearning/light-weight/nas/</link><pubDate>Sat, 03 Jun 2023 18:22:27 +0800</pubDate><guid>https://fengchen321.github.io/posts/deeplearning/light-weight/nas/</guid><category domain="https://fengchen321.github.io/categories/deep-learning/">Deep Learning</category><description>&lt;h2 id="mnasnet" class="heading-element">&lt;span>MnasNet&lt;/span>
 &lt;a href="#mnasnet" class="heading-mark">
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true">&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z">&lt;/path>&lt;/svg>
 &lt;/a>
&lt;/h2>&lt;blockquote>
&lt;p>文章标题：&lt;a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tan_MnasNet_Platform-Aware_Neural_Architecture_Search_for_Mobile_CVPR_2019_paper"target="_blank" rel="external nofollow noopener noreferrer">MnasNet: Platform-Aware Neural Architecture Search for Mobile&lt;/a>
作者：Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, Quoc V. Le
发表时间：(CVPR 2019)&lt;/p></description></item><item><title>Re-parameterization</title><link>https://fengchen321.github.io/posts/deeplearning/light-weight/re-parameterization/</link><pubDate>Sat, 03 Jun 2023 18:22:27 +0800</pubDate><guid>https://fengchen321.github.io/posts/deeplearning/light-weight/re-parameterization/</guid><category domain="https://fengchen321.github.io/categories/deep-learning/">Deep Learning</category><description>&lt;h2 id="acnet" class="heading-element">&lt;span>ACNet&lt;/span>
 &lt;a href="#acnet" class="heading-mark">
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true">&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z">&lt;/path>&lt;/svg>
 &lt;/a>
&lt;/h2>&lt;blockquote>
&lt;p>文章标题：&lt;a href="https://arxiv.org/abs/1908.03930"target="_blank" rel="external nofollow noopener noreferrer">ACNet: Strengthening the Kernel Skeletons for Powerful CNN via Asymmetric Convolution Blocks&lt;/a>&lt;/p></description></item><item><title>ShuffleNet</title><link>https://fengchen321.github.io/posts/deeplearning/light-weight/shufflenet/</link><pubDate>Sat, 03 Jun 2023 18:22:27 +0800</pubDate><guid>https://fengchen321.github.io/posts/deeplearning/light-weight/shufflenet/</guid><category domain="https://fengchen321.github.io/categories/deep-learning/">Deep Learning</category><description>&lt;h2 id="shufflenetv1" class="heading-element">&lt;span>ShuffleNetV1&lt;/span>
 &lt;a href="#shufflenetv1" class="heading-mark">
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true">&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z">&lt;/path>&lt;/svg>
 &lt;/a>
&lt;/h2>&lt;blockquote>
&lt;p>文章标题：&lt;a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_ShuffleNet_An_Extremely_CVPR_2018_paper.html"target="_blank" rel="external nofollow noopener noreferrer">Shufflenet: An extremely efficient convolutional neural network for mobile devices&lt;/a>
作者：&lt;a href="https://scholar.google.com/citations?user=yuB-cfoAAAAJ&amp;amp;hl=zh-CN&amp;amp;oi=sra"target="_blank" rel="external nofollow noopener noreferrer">Xiangyu Zhang&lt;/a>，&lt;a href="https://scholar.google.com/citations?user=Jv4LCj8AAAAJ&amp;amp;hl=zh-CN&amp;amp;oi=sra"target="_blank" rel="external nofollow noopener noreferrer">Xinyu Zhou&lt;/a>，&lt;a href="https://scholar.google.com/citations?user=SCwGvlUAAAAJ&amp;amp;hl=zh-CN&amp;amp;oi=sra"target="_blank" rel="external nofollow noopener noreferrer">Mengxiao Lin&lt;/a> ，&lt;a href="https://scholar.google.com/citations?user=ALVSZAYAAAAJ&amp;amp;hl=zh-CN&amp;amp;oi=sra"target="_blank" rel="external nofollow noopener noreferrer">Jian Sun&lt;/a> ，Megvii Inc (Face++)
发表时间：(CVPR 2018)&lt;/p></description></item><item><title>SqueezeNet</title><link>https://fengchen321.github.io/posts/deeplearning/light-weight/squeezenet/</link><pubDate>Sat, 03 Jun 2023 18:22:27 +0800</pubDate><guid>https://fengchen321.github.io/posts/deeplearning/light-weight/squeezenet/</guid><category domain="https://fengchen321.github.io/categories/deep-learning/">Deep Learning</category><description>&lt;h2 id="squeezenet" class="heading-element">&lt;span>SqueezeNet&lt;/span>
 &lt;a href="#squeezenet" class="heading-mark">
 &lt;svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true">&lt;path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z">&lt;/path>&lt;/svg>
 &lt;/a>
&lt;/h2>&lt;blockquote>
&lt;p>文章标题：&lt;a href="https://arxiv.org/abs/1602.07360"target="_blank" rel="external nofollow noopener noreferrer">SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &amp;lt;0.5MB model size&lt;/a>
作者：
发表时间：(ICLR 2016)&lt;/p></description></item></channel></rss>